"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[8581],{5610(e){e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Getting Started","items":[{"type":"link","label":"ROS 2 Robotic Nervous System","href":"/hackathon-ai-book/modules/ros2-nervous-system/","docId":"modules/ros2-nervous-system/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1: ROS 2 Robotic Nervous System","items":[{"type":"link","label":"ROS 2 Robotic Nervous System","href":"/hackathon-ai-book/modules/ros2-nervous-system/","docId":"modules/ros2-nervous-system/index","unlisted":false},{"type":"link","label":"ROS 2 Architecture","href":"/hackathon-ai-book/modules/ros2-nervous-system/architecture","docId":"modules/ros2-nervous-system/architecture","unlisted":false},{"type":"link","label":"Nodes and Topics","href":"/hackathon-ai-book/modules/ros2-nervous-system/nodes-topics","docId":"modules/ros2-nervous-system/nodes-topics","unlisted":false},{"type":"link","label":"URDF Modeling","href":"/hackathon-ai-book/modules/ros2-nervous-system/urdf-modeling","docId":"modules/ros2-nervous-system/urdf-modeling","unlisted":false},{"type":"link","label":"AI Integration","href":"/hackathon-ai-book/modules/ros2-nervous-system/ai-integration","docId":"modules/ros2-nervous-system/ai-integration","unlisted":false},{"type":"category","label":"Lab Exercises","items":[{"type":"link","label":"Lab 1.1: ROS 2 Basics","href":"/hackathon-ai-book/modules/lab-exercises/lab-1-1-ros2-basics","docId":"modules/lab-exercises/lab-1-1-ros2-basics","unlisted":false},{"type":"link","label":"Lab 1.1: ROS 2 Setup","href":"/hackathon-ai-book/modules/lab-exercises/lab-1-1-ros2-setup","docId":"modules/lab-exercises/lab-1-1-ros2-setup","unlisted":false},{"type":"link","label":"Lab 1.2: Services and Actions","href":"/hackathon-ai-book/modules/lab-exercises/lab-1-2-ros2-services-actions","docId":"modules/lab-exercises/lab-1-2-ros2-services-actions","unlisted":false},{"type":"link","label":"Lab 1.3: Robot State Management","href":"/hackathon-ai-book/modules/lab-exercises/lab-1-3-robot-state-management","docId":"modules/lab-exercises/lab-1-3-robot-state-management","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"References","href":"/hackathon-ai-book/modules/ros2-nervous-system/references","docId":"modules/ros2-nervous-system/references","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin (Gazebo + Unity)","items":[{"type":"link","label":"Digital Twin (Gazebo + Unity)","href":"/hackathon-ai-book/modules/digital-twin/","docId":"modules/digital-twin/index","unlisted":false},{"type":"link","label":"Gazebo Setup","href":"/hackathon-ai-book/modules/digital-twin/gazebo-setup","docId":"modules/digital-twin/gazebo-setup","unlisted":false},{"type":"link","label":"Unity Integration","href":"/hackathon-ai-book/modules/digital-twin/unity-integration","docId":"modules/digital-twin/unity-integration","unlisted":false},{"type":"link","label":"Sensor Simulation","href":"/hackathon-ai-book/modules/digital-twin/sensor-simulation","docId":"modules/digital-twin/sensor-simulation","unlisted":false},{"type":"link","label":"ROS 2 Synchronization","href":"/hackathon-ai-book/modules/digital-twin/ros2-sync","docId":"modules/digital-twin/ros2-sync","unlisted":false},{"type":"category","label":"Lab Exercises","items":[{"type":"link","label":"Lab 2.1: Gazebo Setup","href":"/hackathon-ai-book/modules/lab-exercises/lab-2-1-gazebo-setup","docId":"modules/lab-exercises/lab-2-1-gazebo-setup","unlisted":false},{"type":"link","label":"Lab 2.2: Robot Model Integration","href":"/hackathon-ai-book/modules/lab-exercises/lab-2-2-robot-model-integration","docId":"modules/lab-exercises/lab-2-2-robot-model-integration","unlisted":false},{"type":"link","label":"Lab 2.3: Unity Robotics Integration","href":"/hackathon-ai-book/modules/lab-exercises/lab-2-3-unity-robotics-integration","docId":"modules/lab-exercises/lab-2-3-unity-robotics-integration","unlisted":false},{"type":"link","label":"Lab 2.4: Multi-Environment Synchronization","href":"/hackathon-ai-book/modules/lab-exercises/lab-2-4-multi-environment-synchronization","docId":"modules/lab-exercises/lab-2-4-multi-environment-synchronization","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"References","href":"/hackathon-ai-book/modules/digital-twin/references","docId":"modules/digital-twin/references","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"link","label":"AI-Robot Brain (NVIDIA Isaac)","href":"/hackathon-ai-book/modules/ai-robot-brain/","docId":"modules/ai-robot-brain/index","unlisted":false},{"type":"link","label":"Isaac Sim Setup","href":"/hackathon-ai-book/modules/ai-robot-brain/isaac-sim-setup","docId":"modules/ai-robot-brain/isaac-sim-setup","unlisted":false},{"type":"link","label":"Perception Systems","href":"/hackathon-ai-book/modules/ai-robot-brain/perception-systems","docId":"modules/ai-robot-brain/perception-systems","unlisted":false},{"type":"link","label":"Planning and Control","href":"/hackathon-ai-book/modules/ai-robot-brain/planning-control","docId":"modules/ai-robot-brain/planning-control","unlisted":false},{"type":"link","label":"Reinforcement Learning","href":"/hackathon-ai-book/modules/ai-robot-brain/reinforcement-learning","docId":"modules/ai-robot-brain/reinforcement-learning","unlisted":false},{"type":"category","label":"Lab Exercises","items":[{"type":"link","label":"Lab 3.1: Isaac Navigation","href":"/hackathon-ai-book/modules/lab-exercises/lab-3-1-isaac-navigation","docId":"modules/lab-exercises/lab-3-1-isaac-navigation","unlisted":false},{"type":"link","label":"Lab 3.1: Isaac Sim Setup","href":"/hackathon-ai-book/modules/lab-exercises/lab-3-1-isaac-sim-setup","docId":"modules/lab-exercises/lab-3-1-isaac-sim-setup","unlisted":false},{"type":"link","label":"Lab 3.2: Perception Systems","href":"/hackathon-ai-book/modules/lab-exercises/lab-3-2-perception-systems","docId":"modules/lab-exercises/lab-3-2-perception-systems","unlisted":false},{"type":"link","label":"Lab 3.3: Planning and Control","href":"/hackathon-ai-book/modules/lab-exercises/lab-3-3-planning-control","docId":"modules/lab-exercises/lab-3-3-planning-control","unlisted":false},{"type":"link","label":"Lab 3.4: Reinforcement Learning","href":"/hackathon-ai-book/modules/lab-exercises/lab-3-4-reinforcement-learning","docId":"modules/lab-exercises/lab-3-4-reinforcement-learning","unlisted":false},{"type":"link","label":"Lab 3.5: Sim-to-Real Transfer","href":"/hackathon-ai-book/modules/lab-exercises/lab-3-5-sim2real-transfer","docId":"modules/lab-exercises/lab-3-5-sim2real-transfer","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"References","href":"/hackathon-ai-book/modules/ai-robot-brain/references","docId":"modules/ai-robot-brain/references","unlisted":false},{"type":"link","label":"Sim-to-Real Transfer","href":"/hackathon-ai-book/modules/ai-robot-brain/sim2real","docId":"modules/ai-robot-brain/sim2real","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","label":"Vision-Language-Action (VLA) Systems","href":"/hackathon-ai-book/modules/vla-system/","docId":"modules/vla-system/index","unlisted":false},{"type":"link","label":"VLA Fundamentals","href":"/hackathon-ai-book/modules/vla-system/vla-fundamentals","docId":"modules/vla-system/vla-fundamentals","unlisted":false},{"type":"link","label":"VLA Architecture","href":"/hackathon-ai-book/modules/vla-system/vla-architecture","docId":"modules/vla-system/vla-architecture","unlisted":false},{"type":"link","label":"Multimodal Perception","href":"/hackathon-ai-book/modules/vla-system/multimodal-perception","docId":"modules/vla-system/multimodal-perception","unlisted":false},{"type":"link","label":"Language-Action Mapping","href":"/hackathon-ai-book/modules/vla-system/language-action-mapping","docId":"modules/vla-system/language-action-mapping","unlisted":false},{"type":"link","label":"Training VLA Models","href":"/hackathon-ai-book/modules/vla-system/training-vla-models","docId":"modules/vla-system/training-vla-models","unlisted":false},{"type":"link","label":"VLA Integration","href":"/hackathon-ai-book/modules/vla-system/vla-integration","docId":"modules/vla-system/vla-integration","unlisted":false},{"type":"category","label":"Lab Exercises","items":[{"type":"link","label":"Lab 4.1: VLA Fundamentals","href":"/hackathon-ai-book/modules/lab-exercises/lab-4-1-vla-fundamentals","docId":"modules/lab-exercises/lab-4-1-vla-fundamentals","unlisted":false},{"type":"link","label":"Lab 4.2: Multimodal Perception","href":"/hackathon-ai-book/modules/lab-exercises/lab-4-2-multimodal-perception","docId":"modules/lab-exercises/lab-4-2-multimodal-perception","unlisted":false},{"type":"link","label":"Lab 4.3: Action Mapping","href":"/hackathon-ai-book/modules/lab-exercises/lab-4-3-action-mapping","docId":"modules/lab-exercises/lab-4-3-action-mapping","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"References","href":"/hackathon-ai-book/modules/vla-system/references","docId":"modules/vla-system/references","unlisted":false},{"type":"link","label":"Safety and Evaluation","href":"/hackathon-ai-book/modules/vla-system/safety-evaluation","docId":"modules/vla-system/safety-evaluation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Reference","items":[{"type":"link","label":"Lab Exercises","href":"/hackathon-ai-book/modules/lab-exercises/","docId":"modules/lab-exercises/index","unlisted":false},{"type":"link","label":"Glossary","href":"/hackathon-ai-book/reference/glossary","docId":"reference/glossary","unlisted":false},{"type":"link","label":"Citations","href":"/hackathon-ai-book/reference/citations","docId":"reference/citations","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"Roadmap","href":"/hackathon-ai-book/roadmap","docId":"roadmap","unlisted":false}]},"docs":{"index":{"id":"index","title":"Physical AI & Humanoid Robotics Technical Book","description":"Welcome to the comprehensive guide to embodied AI and humanoid robotics. This book covers everything from basic ROS 2 concepts to advanced AI integration, digital twins, and vision-language-action systems."},"modules/ai-robot-brain/index":{"id":"modules/ai-robot-brain/index","title":"Module 3: AI-Robot Brain (NVIDIA Isaac)","description":"This module covers the implementation of AI systems for robot control using NVIDIA Isaac.","sidebar":"tutorialSidebar"},"modules/ai-robot-brain/isaac-sim-setup":{"id":"modules/ai-robot-brain/isaac-sim-setup","title":"NVIDIA Isaac Sim Setup","description":"This document covers setting up NVIDIA Isaac Sim for robot AI development.","sidebar":"tutorialSidebar"},"modules/ai-robot-brain/perception-systems":{"id":"modules/ai-robot-brain/perception-systems","title":"Perception Systems in AI-Robot Brain","description":"This document covers the implementation of perception systems for robot AI.","sidebar":"tutorialSidebar"},"modules/ai-robot-brain/planning-control":{"id":"modules/ai-robot-brain/planning-control","title":"Planning and Control in AI-Robot Brain","description":"This document covers robot planning and control systems within the AI-Robot Brain.","sidebar":"tutorialSidebar"},"modules/ai-robot-brain/references":{"id":"modules/ai-robot-brain/references","title":"References for AI-Robot Brain Module","description":"This page contains references and additional resources for the AI-Robot Brain module.","sidebar":"tutorialSidebar"},"modules/ai-robot-brain/reinforcement-learning":{"id":"modules/ai-robot-brain/reinforcement-learning","title":"Reinforcement Learning in AI-Robot Brain","description":"This document covers reinforcement learning techniques for robot AI systems.","sidebar":"tutorialSidebar"},"modules/ai-robot-brain/sim2real":{"id":"modules/ai-robot-brain/sim2real","title":"Sim-to-Real Transfer in AI-Robot Brain","description":"This document covers techniques for transferring AI models trained in simulation to real robot systems.","sidebar":"tutorialSidebar"},"modules/digital-twin/gazebo-setup":{"id":"modules/digital-twin/gazebo-setup","title":"Gazebo Setup for Digital Twin","description":"This document covers setting up Gazebo for creating a digital twin environment.","sidebar":"tutorialSidebar"},"modules/digital-twin/index":{"id":"modules/digital-twin/index","title":"Module 2: Digital Twin (Gazebo + Unity)","description":"This module covers the creation and use of digital twins for humanoid robots using Gazebo and Unity.","sidebar":"tutorialSidebar"},"modules/digital-twin/references":{"id":"modules/digital-twin/references","title":"References for Digital Twin Module","description":"This page contains references and additional resources for the Digital Twin module.","sidebar":"tutorialSidebar"},"modules/digital-twin/ros2-sync":{"id":"modules/digital-twin/ros2-sync","title":"ROS 2 Synchronization with Digital Twin","description":"This document covers synchronizing the digital twin environment with ROS 2 systems.","sidebar":"tutorialSidebar"},"modules/digital-twin/sensor-simulation":{"id":"modules/digital-twin/sensor-simulation","title":"Sensor Simulation in Digital Twin","description":"This document covers simulating various robot sensors in the digital twin environment.","sidebar":"tutorialSidebar"},"modules/digital-twin/unity-integration":{"id":"modules/digital-twin/unity-integration","title":"Unity Integration for Digital Twin","description":"This document covers integrating Unity with the ROS 2 ecosystem for digital twin applications.","sidebar":"tutorialSidebar"},"modules/lab-exercises/index":{"id":"modules/lab-exercises/index","title":"Lab Exercises for Physical AI & Humanoid Robotics","description":"This section contains hands-on lab exercises that complement the theoretical concepts covered in each module. These exercises are designed to provide practical experience with ROS 2, Gazebo, Unity, NVIDIA Isaac, and Vision-Language-Action systems.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-1-1-ros2-basics":{"id":"modules/lab-exercises/lab-1-1-ros2-basics","title":"Lab Exercise 1.1: ROS 2 Basics","description":"This lab exercise introduces the fundamental concepts of ROS 2.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-1-1-ros2-setup":{"id":"modules/lab-exercises/lab-1-1-ros2-setup","title":"Lab Exercise 1.1: ROS 2 Setup","description":"This lab exercise guides you through setting up ROS 2 on your system.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-1-2-ros2-services-actions":{"id":"modules/lab-exercises/lab-1-2-ros2-services-actions","title":"Lab Exercise 1.2: ROS 2 Services and Actions","description":"This lab exercise covers services and actions in ROS 2.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-1-3-robot-state-management":{"id":"modules/lab-exercises/lab-1-3-robot-state-management","title":"Lab Exercise 1.3: Robot State Management in ROS 2","description":"This lab exercise covers managing robot states in ROS 2, including joint states, transforms, and robot state publishing.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-2-1-gazebo-setup":{"id":"modules/lab-exercises/lab-2-1-gazebo-setup","title":"Lab Exercise 2.1: Gazebo Setup for Digital Twin","description":"This lab exercise guides you through setting up Gazebo for creating a digital twin environment.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-2-2-robot-model-integration":{"id":"modules/lab-exercises/lab-2-2-robot-model-integration","title":"Lab Exercise 2.2: Robot Model Integration in Gazebo","description":"This lab exercise covers integrating robot models with Gazebo simulation and ROS 2.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-2-3-unity-robotics-integration":{"id":"modules/lab-exercises/lab-2-3-unity-robotics-integration","title":"Lab Exercise 2.3: Unity Robotics Integration","description":"This lab exercise covers integrating Unity with ROS 2 for digital twin applications.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-2-4-multi-environment-synchronization":{"id":"modules/lab-exercises/lab-2-4-multi-environment-synchronization","title":"Lab Exercise 2.4: Multi-Environment Synchronization","description":"This lab exercise covers synchronizing robot states and behaviors across multiple simulation environments (Gazebo and Unity).","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-3-1-isaac-navigation":{"id":"modules/lab-exercises/lab-3-1-isaac-navigation","title":"Lab Exercise 3.1: NVIDIA Isaac Navigation","description":"This lab exercise covers setting up and using NVIDIA Isaac for robot navigation tasks.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-3-1-isaac-sim-setup":{"id":"modules/lab-exercises/lab-3-1-isaac-sim-setup","title":"Lab Exercise 3.1: NVIDIA Isaac Sim Setup","description":"This lab exercise guides you through setting up NVIDIA Isaac Sim for robotics simulation and AI development.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-3-2-perception-systems":{"id":"modules/lab-exercises/lab-3-2-perception-systems","title":"Lab Exercise 3.2: Perception Systems in AI-Robot Brain","description":"This lab exercise covers implementing perception systems for robot AI using NVIDIA Isaac.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-3-3-planning-control":{"id":"modules/lab-exercises/lab-3-3-planning-control","title":"Lab Exercise 3.3: Planning and Control in AI-Robot Brain","description":"This lab exercise covers implementing planning and control systems for robot AI using NVIDIA Isaac.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-3-4-reinforcement-learning":{"id":"modules/lab-exercises/lab-3-4-reinforcement-learning","title":"Lab Exercise 3.4: Reinforcement Learning in AI-Robot Brain","description":"This lab exercise covers implementing reinforcement learning for robot control using NVIDIA Isaac.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-3-5-sim2real-transfer":{"id":"modules/lab-exercises/lab-3-5-sim2real-transfer","title":"Lab Exercise 3.5: Sim-to-Real Transfer in AI-Robot Brain","description":"This lab exercise covers techniques for transferring AI models trained in simulation to real robot systems.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-4-1-vla-fundamentals":{"id":"modules/lab-exercises/lab-4-1-vla-fundamentals","title":"Lab Exercise 4.1: Vision-Language-Action Fundamentals","description":"This lab exercise covers the fundamental concepts of Vision-Language-Action systems and their implementation.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-4-2-multimodal-perception":{"id":"modules/lab-exercises/lab-4-2-multimodal-perception","title":"Lab Exercise 4.2: Multimodal Perception in VLA Systems","description":"This lab exercise covers implementing multimodal perception systems that integrate vision, language, and other sensory inputs for VLA systems.","sidebar":"tutorialSidebar"},"modules/lab-exercises/lab-4-3-action-mapping":{"id":"modules/lab-exercises/lab-4-3-action-mapping","title":"Lab Exercise 4.3: Action Mapping in VLA Systems","description":"This lab exercise covers implementing action mapping systems that translate multimodal perceptions into executable robot actions.","sidebar":"tutorialSidebar"},"modules/ros2-nervous-system/ai-integration":{"id":"modules/ros2-nervous-system/ai-integration","title":"AI Integration with ROS 2","description":"This document covers how to integrate AI systems with the ROS 2 robotic nervous system.","sidebar":"tutorialSidebar"},"modules/ros2-nervous-system/architecture":{"id":"modules/ros2-nervous-system/architecture","title":"ROS 2 Architecture","description":"This document covers the architecture of the ROS 2 robotic nervous system.","sidebar":"tutorialSidebar"},"modules/ros2-nervous-system/index":{"id":"modules/ros2-nervous-system/index","title":"Module 1: ROS 2 Robotic Nervous System","description":"This module covers the ROS 2 (Robot Operating System 2) framework as the nervous system for humanoid robots.","sidebar":"tutorialSidebar"},"modules/ros2-nervous-system/nodes-topics":{"id":"modules/ros2-nervous-system/nodes-topics","title":"Nodes and Topics in ROS 2","description":"This document explains how nodes and topics work in the ROS 2 system.","sidebar":"tutorialSidebar"},"modules/ros2-nervous-system/references":{"id":"modules/ros2-nervous-system/references","title":"References for ROS 2 Nervous System","description":"This page contains references and additional resources for the ROS 2 module.","sidebar":"tutorialSidebar"},"modules/ros2-nervous-system/urdf-modeling":{"id":"modules/ros2-nervous-system/urdf-modeling","title":"URDF Modeling in ROS 2","description":"URDF (Unified Robot Description Format) is used in ROS 2 to describe robot models.","sidebar":"tutorialSidebar"},"modules/vla-system/index":{"id":"modules/vla-system/index","title":"Module 4: Vision-Language-Action (VLA) Systems","description":"This module covers Vision-Language-Action systems that integrate visual perception, natural language understanding, and robotic action control.","sidebar":"tutorialSidebar"},"modules/vla-system/language-action-mapping":{"id":"modules/vla-system/language-action-mapping","title":"Language-Action Mapping in VLA Systems","description":"This document covers the critical component of mapping natural language commands to executable robotic actions in Vision-Language-Action systems.","sidebar":"tutorialSidebar"},"modules/vla-system/multimodal-perception":{"id":"modules/vla-system/multimodal-perception","title":"Multimodal Perception in VLA Systems","description":"This document covers the integration of multiple sensory modalities for enhanced robot perception in Vision-Language-Action systems.","sidebar":"tutorialSidebar"},"modules/vla-system/references":{"id":"modules/vla-system/references","title":"References for VLA Systems Module","description":"This page contains references and additional resources for the Vision-Language-Action Systems module.","sidebar":"tutorialSidebar"},"modules/vla-system/safety-evaluation":{"id":"modules/vla-system/safety-evaluation","title":"Safety and Evaluation in VLA Systems","description":"This document covers safety considerations and evaluation methodologies for Vision-Language-Action systems.","sidebar":"tutorialSidebar"},"modules/vla-system/training-vla-models":{"id":"modules/vla-system/training-vla-models","title":"Training Vision-Language-Action Models","description":"This document covers the methodologies and best practices for training Vision-Language-Action models.","sidebar":"tutorialSidebar"},"modules/vla-system/vla-architecture":{"id":"modules/vla-system/vla-architecture","title":"Vision-Language-Action (VLA) Architecture","description":"This document covers the architectural patterns and components of Vision-Language-Action systems.","sidebar":"tutorialSidebar"},"modules/vla-system/vla-fundamentals":{"id":"modules/vla-system/vla-fundamentals","title":"Vision-Language-Action (VLA) Fundamentals","description":"This document covers the fundamental concepts of Vision-Language-Action systems.","sidebar":"tutorialSidebar"},"modules/vla-system/vla-integration":{"id":"modules/vla-system/vla-integration","title":"Vision-Language-Action System Integration","description":"This document covers the integration of Vision-Language-Action components into a cohesive robotic system.","sidebar":"tutorialSidebar"},"reference/citations":{"id":"reference/citations","title":"Citations and References","description":"This page contains citations and references for the Physical AI & Humanoid Robotics Technical Book.","sidebar":"tutorialSidebar"},"reference/glossary":{"id":"reference/glossary","title":"Glossary","description":"This glossary defines key terms used throughout the Physical AI & Humanoid Robotics Technical Book.","sidebar":"tutorialSidebar"},"roadmap":{"id":"roadmap","title":"Roadmap: Physical AI & Humanoid Robotics Technical Book","description":"Overview","sidebar":"tutorialSidebar"}}}')}}]);