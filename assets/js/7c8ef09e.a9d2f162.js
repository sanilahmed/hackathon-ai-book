"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[7240],{548(e,s,n){n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>c});var i=n(4848),a=n(8453);const r={sidebar_label:"References"},t="References for VLA Systems Module",o={id:"modules/vla-system/references",title:"References for VLA Systems Module",description:"This page contains references and additional resources for the Vision-Language-Action Systems module.",source:"@site/docs/modules/vla-system/references.md",sourceDirName:"modules/vla-system",slug:"/modules/vla-system/references",permalink:"/hackathon-ai-book/modules/vla-system/references",draft:!1,unlisted:!1,editUrl:"https://github.com/sanilahmed/hackathon-ai-book/tree/main/docs/modules/vla-system/references.md",tags:[],version:"current",frontMatter:{sidebar_label:"References"},sidebar:"tutorialSidebar",previous:{title:"Lab 4.3: Action Mapping",permalink:"/hackathon-ai-book/modules/lab-exercises/lab-4-3-action-mapping"},next:{title:"Safety and Evaluation",permalink:"/hackathon-ai-book/modules/vla-system/safety-evaluation"}},l={},c=[{value:"Research Papers",id:"research-papers",level:2},{value:"NVIDIA Isaac Resources",id:"nvidia-isaac-resources",level:2},{value:"Frameworks and Libraries",id:"frameworks-and-libraries",level:2},{value:"Datasets",id:"datasets",level:2},{value:"Evaluation and Safety",id:"evaluation-and-safety",level:2},{value:"Tutorials and Courses",id:"tutorials-and-courses",level:2},{value:"Community Resources",id:"community-resources",level:2},{value:"Related Technologies",id:"related-technologies",level:2}];function d(e){const s={a:"a",h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.h1,{id:"references-for-vla-systems-module",children:"References for VLA Systems Module"}),"\n",(0,i.jsx)(s.p,{children:"This page contains references and additional resources for the Vision-Language-Action Systems module."}),"\n",(0,i.jsx)(s.h2,{id:"research-papers",children:"Research Papers"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:'"Vision-Language-Action Models for Embodied AI" - NeurIPS 2023'}),"\n",(0,i.jsx)(s.li,{children:'"RT-1: Robotics Transformer for Real-World Control at Scale" - arXiv 2023'}),"\n",(0,i.jsx)(s.li,{children:'"Language-Conditioned Learning for Robotic Manipulation" - ICML 2022'}),"\n",(0,i.jsx)(s.li,{children:'"Embodied AI: Past, Present, and Future" - Science Robotics 2023'}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"nvidia-isaac-resources",children:"NVIDIA Isaac Resources"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://isaac-sim.github.io/IsaacLab/",children:"Isaac Lab Documentation"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://nvidia-isaac-ros.github.io/research_and_dev/navigation/index.html",children:"Isaac ROS Navigation"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/tutorial_index.html",children:"Isaac Sim Tutorials"})}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"frameworks-and-libraries",children:"Frameworks and Libraries"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://github.com/openai/CLIP",children:"CLIP"})," - Contrastive Language-Image Pretraining"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://github.com/openvla/openvla",children:"OpenVLA"})," - Open Vision-Language-Action Models"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://roboturk.stanford.edu/",children:"RoboTurk"})," - Robotic Learning Environment"]}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://github.com/StanfordVL/manipulation-learning",children:"Manipulation Learning"})}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"datasets",children:"Datasets"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://github.com/ImperialCollegeLondon/bridge_data_v2",children:"Bridge Data"})," - Human demonstration dataset"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://robotics-transformer-x.github.io/",children:"Open X-Embodiment"})," - Multi-robot dataset"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://tonyzhaozh.github.io/aloha/",children:"ALOHA"})," - Bimanual manipulation dataset"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://robotics-transformer-x.github.io/",children:"RT-1X"})," - Large-scale robot dataset"]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"evaluation-and-safety",children:"Evaluation and Safety"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://safeai.gatech.edu/",children:"AI Safety Guidelines"})," - AI safety research"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://www.iso.org/standard/42096.html",children:"Robot Safety Standards"})," - ISO 10218 for industrial robots"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://www.iso.org/standard/55228.html",children:"Personal Care Robots Standard"})," - ISO 13482 for service robots"]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"tutorials-and-courses",children:"Tutorials and Courses"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://cs328-stanford.github.io/fall2023/",children:"Stanford CS328: Embodied AI"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://rl4real.gatech.edu/",children:"UT Austin Robot Learning Course"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://cmu-rlcourse.github.io/",children:"CMU Robotic AI Course"})}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"community-resources",children:"Community Resources"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.a,{href:"https://embodied-ai.org/",children:"Embodied AI Workshop"})," - Annual workshop"]}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://robotics.stackexchange.com/",children:"Robotics Stack Exchange"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://answers.ros.org/questions/",children:"ROS Answers"})}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"related-technologies",children:"Related Technologies"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://huggingface.co/models?pipeline_tag=visual-question-answering",children:"Transformers for Vision and Language"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://docs.ros.org/en/humble/",children:"Robot Operating System 2"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://pytorch.org/",children:"PyTorch for Robotics"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"https://robotics.farama.org/",children:"OpenAI Gym for Robotics"})}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453(e,s,n){n.d(s,{R:()=>t,x:()=>o});var i=n(6540);const a={},r=i.createContext(a);function t(e){const s=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),i.createElement(r.Provider,{value:s},e.children)}}}]);