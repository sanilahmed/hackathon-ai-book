"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[1852],{4855(e,n,a){a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>t,metadata:()=>o,toc:()=>d});var i=a(4848),r=a(8453);const t={sidebar_label:"Lab 3.5: Sim-to-Real Transfer"},s="Lab Exercise 3.5: Sim-to-Real Transfer in AI-Robot Brain",o={id:"modules/lab-exercises/lab-3-5-sim2real-transfer",title:"Lab Exercise 3.5: Sim-to-Real Transfer in AI-Robot Brain",description:"This lab exercise covers techniques for transferring AI models trained in simulation to real robot systems.",source:"@site/docs/modules/lab-exercises/lab-3-5-sim2real-transfer.md",sourceDirName:"modules/lab-exercises",slug:"/modules/lab-exercises/lab-3-5-sim2real-transfer",permalink:"/hackathon-ai-book/modules/lab-exercises/lab-3-5-sim2real-transfer",draft:!1,unlisted:!1,editUrl:"https://github.com/sanilahmed/hackathon-ai-book/tree/main/docs/modules/lab-exercises/lab-3-5-sim2real-transfer.md",tags:[],version:"current",frontMatter:{sidebar_label:"Lab 3.5: Sim-to-Real Transfer"},sidebar:"tutorialSidebar",previous:{title:"Lab 3.4: Reinforcement Learning",permalink:"/hackathon-ai-book/modules/lab-exercises/lab-3-4-reinforcement-learning"},next:{title:"References",permalink:"/hackathon-ai-book/modules/ai-robot-brain/references"}},l={},d=[{value:"Objectives",id:"objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Reality Gap Overview",id:"reality-gap-overview",level:2},{value:"The Simulation-to-Reality Problem",id:"the-simulation-to-reality-problem",level:3},{value:"Transfer Learning Approaches",id:"transfer-learning-approaches",level:3},{value:"Domain Randomization Implementation",id:"domain-randomization-implementation",level:2},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"Physics Domain Randomization",id:"physics-domain-randomization",level:3},{value:"Domain Adaptation Techniques",id:"domain-adaptation-techniques",level:2},{value:"Unsupervised Domain Adaptation",id:"unsupervised-domain-adaptation",level:3},{value:"Sim-to-Real Transfer Pipeline",id:"sim-to-real-transfer-pipeline",level:2},{value:"Transfer Learning Node",id:"transfer-learning-node",level:3},{value:"Progressive Domain Randomization",id:"progressive-domain-randomization",level:2},{value:"Adaptive Randomization",id:"adaptive-randomization",level:3},{value:"System Identification for Sim-to-Real",id:"system-identification-for-sim-to-real",level:2},{value:"Dynamics Model Learning",id:"dynamics-model-learning",level:3},{value:"Real Robot Testing",id:"real-robot-testing",level:2},{value:"Hardware Interface Node",id:"hardware-interface-node",level:3},{value:"Transfer Evaluation",id:"transfer-evaluation",level:2},{value:"Performance Comparison",id:"performance-comparison",level:3},{value:"Exercise Tasks",id:"exercise-tasks",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Summary",id:"summary",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"lab-exercise-35-sim-to-real-transfer-in-ai-robot-brain",children:"Lab Exercise 3.5: Sim-to-Real Transfer in AI-Robot Brain"}),"\n",(0,i.jsx)(n.p,{children:"This lab exercise covers techniques for transferring AI models trained in simulation to real robot systems."}),"\n",(0,i.jsx)(n.h2,{id:"objectives",children:"Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understand the reality gap problem"}),"\n",(0,i.jsx)(n.li,{children:"Implement domain randomization techniques"}),"\n",(0,i.jsx)(n.li,{children:"Apply domain adaptation methods"}),"\n",(0,i.jsx)(n.li,{children:"Test sim-to-real transfer with real robots"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Isaac Sim environment"}),"\n",(0,i.jsx)(n.li,{children:"Real robot (or simulated with realistic physics)"}),"\n",(0,i.jsx)(n.li,{children:"Completed RL and perception labs"}),"\n",(0,i.jsx)(n.li,{children:"Basic understanding of transfer learning"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"reality-gap-overview",children:"Reality Gap Overview"}),"\n",(0,i.jsx)(n.h3,{id:"the-simulation-to-reality-problem",children:"The Simulation-to-Reality Problem"}),"\n",(0,i.jsx)(n.p,{children:"The reality gap includes differences in:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Visual appearance"}),": Lighting, textures, colors"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Physics simulation"}),": Friction, compliance, dynamics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor characteristics"}),": Noise, latency, resolution"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuator behavior"}),": Delays, inaccuracies, limitations"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"transfer-learning-approaches",children:"Transfer Learning Approaches"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Domain Randomization"}),": Randomize simulation parameters"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Domain Adaptation"}),": Adapt models to new domains"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"System Identification"}),": Learn real-world dynamics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Progressive Transfer"}),": Gradually reduce randomization"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"domain-randomization-implementation",children:"Domain Randomization Implementation"}),"\n",(0,i.jsx)(n.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import random\nimport numpy as np\nimport cv2\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.materials import OmniPBR\n\nclass VisualDomainRandomizer:\n    def __init__(self):\n        self.light_properties = {\n            'intensity_range': (500, 2000),\n            'color_range': [(0.8, 0.8, 1.0), (1.0, 0.9, 0.8)],\n            'position_jitter': 0.5\n        }\n\n        self.material_properties = {\n            'roughness_range': (0.1, 0.9),\n            'metallic_range': (0.0, 0.2),\n            'specular_range': (0.1, 0.9)\n        }\n\n    def randomize_lighting(self):\n        \"\"\"Randomize lighting conditions in simulation\"\"\"\n        # Get all lights in the scene\n        lights = self.get_all_lights()\n\n        for light in lights:\n            # Randomize intensity\n            intensity = random.uniform(\n                self.light_properties['intensity_range'][0],\n                self.light_properties['intensity_range'][1]\n            )\n            light.set_attribute('intensity', intensity)\n\n            # Randomize color\n            color = random.choice(self.light_properties['color_range'])\n            light.set_attribute('color', color)\n\n            # Randomize position slightly\n            current_pos = light.get_world_pose()[0]\n            jitter = np.random.uniform(\n                -self.light_properties['position_jitter'],\n                self.light_properties['position_jitter'],\n                size=3\n            )\n            new_pos = current_pos + jitter\n            light.set_world_pose(position=new_pos)\n\n    def randomize_materials(self):\n        \"\"\"Randomize material properties\"\"\"\n        # Get all objects in the scene\n        objects = self.get_all_objects()\n\n        for obj in objects:\n            # Get current material\n            material = obj.get_material()\n\n            # Randomize material properties\n            if material:\n                roughness = random.uniform(\n                    self.material_properties['roughness_range'][0],\n                    self.material_properties['roughness_range'][1]\n                )\n                material.set_attribute('roughness', roughness)\n\n                metallic = random.uniform(\n                    self.material_properties['metallic_range'][0],\n                    self.material_properties['metallic_range'][1]\n                )\n                material.set_attribute('metallic', metallic)\n\n    def randomize_textures(self):\n        \"\"\"Randomize object textures\"\"\"\n        # Apply random textures to objects\n        objects = self.get_all_objects()\n\n        for obj in objects:\n            # Randomly select from a set of textures\n            texture_options = [\n                '/Isaac/Textures/rough.png',\n                '/Isaac/Textures/smooth.png',\n                '/Isaac/Textures/metal.png',\n                '/Isaac/Textures/plastic.png'\n            ]\n\n            random_texture = random.choice(texture_options)\n            obj.set_texture(random_texture)\n\n    def get_all_lights(self):\n        \"\"\"Get all light objects in the scene\"\"\"\n        # Implementation depends on your specific scene setup\n        return []\n\n    def get_all_objects(self):\n        \"\"\"Get all objects in the scene\"\"\"\n        # Implementation depends on your specific scene setup\n        return []\n"})}),"\n",(0,i.jsx)(n.h3,{id:"physics-domain-randomization",children:"Physics Domain Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class PhysicsDomainRandomizer:\n    def __init__(self):\n        self.physics_params = {\n            'friction_range': (0.1, 1.0),\n            'restitution_range': (0.0, 0.5),\n            'mass_multiplier_range': (0.8, 1.2),\n            'damping_range': (0.01, 0.1)\n        }\n\n    def randomize_physics_properties(self, robot):\n        \"\"\"Randomize physics properties of robot and environment\"\"\"\n        # Randomize robot joint friction\n        joint_names = robot.get_joint_names()\n        for joint_name in joint_names:\n            friction = random.uniform(\n                self.physics_params['friction_range'][0],\n                self.physics_params['friction_range'][1]\n            )\n            robot.set_joint_friction(joint_name, friction)\n\n        # Randomize link masses\n        link_names = robot.get_link_names()\n        for link_name in link_names:\n            current_mass = robot.get_link_mass(link_name)\n            mass_multiplier = random.uniform(\n                self.physics_params['mass_multiplier_range'][0],\n                self.physics_params['mass_multiplier_range'][1]\n            )\n            new_mass = current_mass * mass_multiplier\n            robot.set_link_mass(link_name, new_mass)\n\n        # Randomize damping\n        for joint_name in joint_names:\n            damping = random.uniform(\n                self.physics_params['damping_range'][0],\n                self.physics_params['damping_range'][1]\n            )\n            robot.set_joint_damping(joint_name, damping)\n\n    def randomize_environment_physics(self):\n        \"\"\"Randomize environment physics properties\"\"\"\n        # Randomize ground friction\n        ground_friction = random.uniform(\n            self.physics_params['friction_range'][0],\n            self.physics_params['friction_range'][1]\n        )\n\n        # Randomize gravity slightly\n        gravity_jitter = np.random.uniform(-0.5, 0.5, size=3)\n        # Apply gravity jitter to simulation\n"})}),"\n",(0,i.jsx)(n.h2,{id:"domain-adaptation-techniques",children:"Domain Adaptation Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"unsupervised-domain-adaptation",children:"Unsupervised Domain Adaptation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nclass DomainAdaptationNetwork(nn.Module):\n    def __init__(self, input_dim, feature_dim=256, num_classes=10):\n        super(DomainAdaptationNetwork, self).__init__()\n\n        # Feature extractor\n        self.feature_extractor = nn.Sequential(\n            nn.Linear(input_dim, feature_dim),\n            nn.ReLU(),\n            nn.Linear(feature_dim, feature_dim),\n            nn.ReLU()\n        )\n\n        # Label classifier\n        self.label_classifier = nn.Sequential(\n            nn.Linear(feature_dim, feature_dim),\n            nn.ReLU(),\n            nn.Linear(feature_dim, num_classes)\n        )\n\n        # Domain classifier\n        self.domain_classifier = nn.Sequential(\n            nn.Linear(feature_dim, feature_dim),\n            nn.ReLU(),\n            nn.Linear(feature_dim, 2)  # 2 domains: source and target\n        )\n\n    def forward(self, x, alpha=0):\n        # Extract features\n        features = self.feature_extractor(x)\n\n        # Reverse gradients for domain adaptation\n        reverse_features = self.gradient_reverse_layer(features, alpha)\n\n        # Get predictions\n        class_pred = self.label_classifier(features)\n        domain_pred = self.domain_classifier(reverse_features)\n\n        return class_pred, domain_pred\n\n    def gradient_reverse_layer(self, x, alpha):\n        """Gradient reversal layer for domain adaptation"""\n        return GradientReverseFunction.apply(x, alpha)\n\nclass GradientReverseFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input, alpha):\n        ctx.alpha = alpha\n        return input\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n        return output, None\n\nclass DomainAdaptationTrainer:\n    def __init__(self, model, learning_rate=1e-3):\n        self.model = model\n        self.classifier_criterion = nn.CrossEntropyLoss()\n        self.domain_criterion = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    def train_step(self, source_data, target_data, labels_s, alpha=0.1):\n        """Single training step for domain adaptation"""\n        # Zero gradients\n        self.optimizer.zero_grad()\n\n        # Source domain\n        class_pred_s, domain_pred_s = self.model(source_data, alpha=0)\n        source_domain_labels = torch.zeros(source_data.size(0), dtype=torch.long)\n\n        # Target domain\n        class_pred_t, domain_pred_t = self.model(target_data, alpha=alpha)\n        target_domain_labels = torch.ones(target_data.size(0), dtype=torch.long)\n\n        # Compute losses\n        class_loss = self.classifier_criterion(class_pred_s, labels_s)\n        domain_loss = (self.domain_criterion(domain_pred_s, source_domain_labels) +\n                      self.domain_criterion(domain_pred_t, target_domain_labels))\n\n        total_loss = class_loss + domain_loss\n\n        # Backward pass\n        total_loss.backward()\n        self.optimizer.step()\n\n        return total_loss.item(), class_loss.item(), domain_loss.item()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"sim-to-real-transfer-pipeline",children:"Sim-to-Real Transfer Pipeline"}),"\n",(0,i.jsx)(n.h3,{id:"transfer-learning-node",children:"Transfer Learning Node"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, LaserScan\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Float32\nfrom cv_bridge import CvBridge\nimport torch\nimport numpy as np\n\nclass Sim2RealTransferNode(Node):\n    def __init__(self):\n        super().__init__(\'sim2real_transfer\')\n\n        # Initialize CV bridge\n        self.cv_bridge = CvBridge()\n\n        # Publishers and subscribers\n        self.image_sub = self.create_subscription(Image, \'/camera/image_raw\', self.image_callback, 10)\n        self.laser_sub = self.create_subscription(LaserScan, \'/scan\', self.laser_callback, 10)\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.transfer_quality_pub = self.create_publisher(Float32, \'/transfer_quality\', 10)\n\n        # Load pre-trained simulation model\n        self.sim_model = self.load_pretrained_model(\'sim_model.pth\')\n\n        # Initialize real-world adaptation model\n        self.real_model = self.create_adapted_model(self.sim_model)\n\n        # Adaptation parameters\n        self.adaptation_active = True\n        self.transfer_quality = 0.0\n\n        # Data buffers for adaptation\n        self.real_data_buffer = []\n        self.buffer_size = 100\n\n    def load_pretrained_model(self, model_path):\n        """Load pre-trained model from simulation"""\n        model = torch.load(model_path)\n        model.eval()\n        return model\n\n    def create_adapted_model(self, sim_model):\n        """Create adapted model for real-world"""\n        # Fine-tune or adapt the simulation model for real-world\n        # This could involve:\n        # - Fine-tuning on real data\n        # - Adding domain adaptation layers\n        # - Adjusting for real sensor characteristics\n        return sim_model  # Simplified for this example\n\n    def image_callback(self, msg):\n        """Process camera image and run inference"""\n        try:\n            # Convert ROS image to OpenCV\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\n\n            # Preprocess image (adjust for real-world sensor characteristics)\n            processed_image = self.preprocess_real_image(cv_image)\n\n            # Run inference\n            action = self.infer_action(processed_image)\n\n            # Publish command\n            cmd_vel = self.convert_action_to_cmd_vel(action)\n            self.cmd_vel_pub.publish(cmd_vel)\n\n            # Collect data for adaptation\n            if self.adaptation_active:\n                self.collect_real_data(processed_image, action)\n\n        except Exception as e:\n            self.get_logger().error(f\'Error processing image: {e}\')\n\n    def laser_callback(self, msg):\n        """Process laser scan data"""\n        # Process laser data for obstacle avoidance\n        ranges = np.array(msg.ranges)\n        # Filter out invalid ranges\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            min_range = np.min(valid_ranges)\n            if min_range < 0.5:  # Emergency stop threshold\n                # Emergency stop\n                cmd_vel = Twist()\n                self.cmd_vel_pub.publish(cmd_vel)\n\n    def preprocess_real_image(self, image):\n        """Preprocess real-world image to match simulation characteristics"""\n        # Adjust for real-world camera characteristics\n        # This might include:\n        # - Color space adjustments\n        # - Noise addition/removal\n        # - Resolution matching\n        # - Distortion correction\n\n        # Example: adjust brightness/contrast to match simulation range\n        adjusted_image = cv2.convertScaleAbs(image, alpha=1.1, beta=10)\n\n        return adjusted_image\n\n    def infer_action(self, processed_image):\n        """Run inference to determine action"""\n        # Convert image to tensor\n        image_tensor = torch.FloatTensor(processed_image).permute(2, 0, 1).unsqueeze(0)\n\n        # Run model inference\n        with torch.no_grad():\n            action_tensor = self.real_model(image_tensor)\n            action = action_tensor.cpu().numpy()\n\n        return action\n\n    def convert_action_to_cmd_vel(self, action):\n        """Convert neural network output to Twist command"""\n        cmd_vel = Twist()\n\n        # Example: action is [linear_vel, angular_vel]\n        if len(action) >= 2:\n            cmd_vel.linear.x = float(action[0])\n            cmd_vel.angular.z = float(action[1])\n\n        return cmd_vel\n\n    def collect_real_data(self, image, action):\n        """Collect real-world data for adaptation"""\n        data_point = {\n            \'image\': image,\n            \'action\': action,\n            \'timestamp\': self.get_clock().now().nanoseconds\n        }\n\n        self.real_data_buffer.append(data_point)\n\n        # Keep buffer size manageable\n        if len(self.real_data_buffer) > self.buffer_size:\n            self.real_data_buffer.pop(0)\n\n    def evaluate_transfer_quality(self):\n        """Evaluate how well the simulation model works in reality"""\n        # This would involve comparing expected vs. actual behavior\n        # For now, return a simple metric based on consistency\n        if len(self.real_data_buffer) < 10:\n            return 0.0\n\n        # Calculate consistency of actions over time\n        recent_actions = [data[\'action\'] for data in self.real_data_buffer[-10:]]\n        action_variance = np.var(recent_actions)\n\n        # Lower variance indicates more consistent behavior (potentially better transfer)\n        quality = max(0.0, 1.0 - action_variance)\n        return min(quality, 1.0)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"progressive-domain-randomization",children:"Progressive Domain Randomization"}),"\n",(0,i.jsx)(n.h3,{id:"adaptive-randomization",children:"Adaptive Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class AdaptiveDomainRandomizer:\n    def __init__(self):\n        self.randomization_strength = 1.0  # Start with high randomization\n        self.performance_threshold = 0.8   # Performance threshold\n        self.min_randomization = 0.1       # Minimum randomization level\n        self.randomization_decay = 0.99    # Decay rate\n\n        self.performance_history = []\n        self.max_history = 50\n\n    def update_randomization(self, current_performance):\n        """Adaptively adjust domain randomization based on performance"""\n        # Add current performance to history\n        self.performance_history.append(current_performance)\n\n        if len(self.performance_history) > self.max_history:\n            self.performance_history.pop(0)\n\n        # Calculate recent average performance\n        if len(self.performance_history) > 10:\n            avg_performance = np.mean(self.performance_history[-10:])\n\n            # If performance is good, reduce randomization\n            if avg_performance > self.performance_threshold:\n                self.randomization_strength *= self.randomization_decay\n                self.randomization_strength = max(\n                    self.randomization_strength,\n                    self.min_randomization\n                )\n            else:\n                # If performance drops, increase randomization\n                self.randomization_strength = min(\n                    self.randomization_strength * 1.01,\n                    1.0\n                )\n\n    def get_randomization_params(self):\n        """Get current randomization parameters"""\n        return {\n            \'lighting_variation\': self.randomization_strength,\n            \'texture_variation\': self.randomization_strength,\n            \'physics_variation\': self.randomization_strength * 0.5,  # Less physics variation\n            \'sensor_noise\': self.randomization_strength\n        }\n'})}),"\n",(0,i.jsx)(n.h2,{id:"system-identification-for-sim-to-real",children:"System Identification for Sim-to-Real"}),"\n",(0,i.jsx)(n.h3,{id:"dynamics-model-learning",children:"Dynamics Model Learning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class DynamicsLearner:\n    def __init__(self):\n        self.sim_dynamics = None  # Simulation dynamics model\n        self.residual_model = None  # Learned residual between sim and real\n        self.data_buffer = []\n        self.buffer_size = 1000\n\n    def collect_data_pair(self, sim_state, real_state, action):\n        """Collect paired simulation and real-world data"""\n        data_point = {\n            \'sim_state\': sim_state,\n            \'real_state\': real_state,\n            \'action\': action,\n            \'residual\': real_state - sim_state  # Simple residual\n        }\n\n        self.data_buffer.append(data_point)\n\n        if len(self.data_buffer) > self.buffer_size:\n            self.data_buffer.pop(0)\n\n    def train_residual_model(self):\n        """Train model to predict simulation-to-reality residual"""\n        if len(self.data_buffer) < 100:\n            return  # Not enough data yet\n\n        # Prepare training data\n        X = []  # State-action pairs\n        y = []  # Residuals\n\n        for data_point in self.data_buffer:\n            state_action = np.concatenate([\n                data_point[\'sim_state\'],\n                data_point[\'action\']\n            ])\n            X.append(state_action)\n            y.append(data_point[\'residual\'])\n\n        X = np.array(X)\n        y = np.array(y)\n\n        # Train residual model (using simple neural network)\n        self.residual_model = self.train_neural_network(X, y)\n\n    def train_neural_network(self, X, y):\n        """Train a neural network to predict residuals"""\n        import torch.nn as nn\n        import torch.optim as optim\n\n        class ResidualNet(nn.Module):\n            def __init__(self, input_dim, output_dim):\n                super().__init__()\n                self.network = nn.Sequential(\n                    nn.Linear(input_dim, 128),\n                    nn.ReLU(),\n                    nn.Linear(128, 128),\n                    nn.ReLU(),\n                    nn.Linear(128, output_dim)\n                )\n\n            def forward(self, x):\n                return self.network(x)\n\n        model = ResidualNet(X.shape[1], y.shape[1])\n        optimizer = optim.Adam(model.parameters())\n        criterion = nn.MSELoss()\n\n        X_tensor = torch.FloatTensor(X)\n        y_tensor = torch.FloatTensor(y)\n\n        for epoch in range(100):\n            optimizer.zero_grad()\n            pred = model(X_tensor)\n            loss = criterion(pred, y_tensor)\n            loss.backward()\n            optimizer.step()\n\n        return model\n\n    def predict_real_state(self, sim_state, action):\n        """Predict real-world state given simulation state and action"""\n        if self.residual_model is None:\n            return sim_state  # If no residual model, return sim state\n\n        state_action = np.concatenate([sim_state, action])\n        state_action_tensor = torch.FloatTensor(state_action).unsqueeze(0)\n\n        with torch.no_grad():\n            residual = self.residual_model(state_action_tensor).numpy().flatten()\n\n        return sim_state + residual\n'})}),"\n",(0,i.jsx)(n.h2,{id:"real-robot-testing",children:"Real Robot Testing"}),"\n",(0,i.jsx)(n.h3,{id:"hardware-interface-node",children:"Hardware Interface Node"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState, Imu\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Odometry\nfrom std_msgs.msg import Bool\nimport numpy as np\n\nclass RealRobotInterface(Node):\n    def __init__(self):\n        super().__init__(\'real_robot_interface\')\n\n        # Robot-specific publishers and subscribers\n        self.joint_state_sub = self.create_subscription(\n            JointState, \'/joint_states\', self.joint_state_callback, 10\n        )\n        self.odom_sub = self.create_subscription(\n            Odometry, \'/odom\', self.odom_callback, 10\n        )\n        self.imu_sub = self.create_subscription(\n            Imu, \'/imu/data\', self.imu_callback, 10\n        )\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.joint_cmd_pub = self.create_publisher(JointState, \'/joint_commands\', 10)\n\n        # Robot state storage\n        self.current_joint_positions = {}\n        self.current_pose = None\n        self.current_twist = None\n        self.current_imu = None\n\n        # Robot parameters (adjust for your specific robot)\n        self.wheel_radius = 0.05  # meters\n        self.wheel_separation = 0.3  # meters\n\n    def joint_state_callback(self, msg):\n        """Update joint state information"""\n        for i, name in enumerate(msg.name):\n            if i < len(msg.position):\n                self.current_joint_positions[name] = msg.position[i]\n\n    def odom_callback(self, msg):\n        """Update odometry information"""\n        self.current_pose = msg.pose.pose\n        self.current_twist = msg.twist.twist\n\n    def imu_callback(self, msg):\n        """Update IMU information"""\n        self.current_imu = msg\n\n    def send_velocity_command(self, linear_vel, angular_vel):\n        """Send velocity command to robot"""\n        cmd_vel = Twist()\n        cmd_vel.linear.x = linear_vel\n        cmd_vel.angular.z = angular_vel\n        self.cmd_vel_pub.publish(cmd_vel)\n\n    def send_joint_commands(self, joint_positions):\n        """Send joint position commands"""\n        joint_cmd = JointState()\n        joint_cmd.header.stamp = self.get_clock().now().to_msg()\n        joint_cmd.name = list(joint_positions.keys())\n        joint_cmd.position = list(joint_positions.values())\n        self.joint_cmd_pub.publish(joint_cmd)\n\n    def get_robot_state(self):\n        """Get current robot state as a feature vector"""\n        if (self.current_pose is None or\n            self.current_twist is None or\n            self.current_imu is None):\n            return None\n\n        # Create state vector [x, y, theta, linear_vel, angular_vel, imu_x, imu_y, imu_z]\n        state = np.array([\n            self.current_pose.position.x,\n            self.current_pose.position.y,\n            self.get_yaw_from_quaternion(self.current_pose.orientation),\n            self.current_twist.linear.x,\n            self.current_twist.angular.z,\n            self.current_imu.linear_acceleration.x,\n            self.current_imu.linear_acceleration.y,\n            self.current_imu.linear_acceleration.z\n        ])\n\n        return state\n\n    def get_yaw_from_quaternion(self, quat):\n        """Convert quaternion to yaw angle"""\n        siny_cosp = 2 * (quat.w * quat.z + quat.x * quat.y)\n        cosy_cosp = 1 - 2 * (quat.y * quat.y + quat.z * quat.z)\n        return np.arctan2(siny_cosp, cosy_cosp)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"transfer-evaluation",children:"Transfer Evaluation"}),"\n",(0,i.jsx)(n.h3,{id:"performance-comparison",children:"Performance Comparison"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class TransferEvaluator:\n    def __init__(self):\n        self.sim_performance = []\n        self.real_performance = []\n        self.transfer_gap = []\n\n    def evaluate_task_performance(self, agent, sim_env, real_env, num_episodes=20):\n        \"\"\"Compare performance in simulation vs. real world\"\"\"\n        # Evaluate in simulation\n        sim_rewards = []\n        for episode in range(num_episodes):\n            state = sim_env.reset()\n            total_reward = 0\n            done = False\n\n            while not done:\n                action = agent.act(state)\n                state, reward, done, _ = sim_env.step(action)\n                total_reward += reward\n\n            sim_rewards.append(total_reward)\n\n        # Evaluate in real world (or realistic simulation)\n        real_rewards = []\n        for episode in range(num_episodes):\n            state = real_env.reset()\n            total_reward = 0\n            done = False\n\n            while not done:\n                action = agent.act(state)\n                state, reward, done, _ = real_env.step(action)\n                total_reward += reward\n\n            real_rewards.append(total_reward)\n\n        # Calculate transfer metrics\n        sim_avg = np.mean(sim_rewards)\n        real_avg = np.mean(real_rewards)\n        gap = (sim_avg - real_avg) / sim_avg if sim_avg != 0 else 0\n\n        self.sim_performance.append(sim_avg)\n        self.real_performance.append(real_avg)\n        self.transfer_gap.append(gap)\n\n        return {\n            'sim_avg_reward': sim_avg,\n            'real_avg_reward': real_avg,\n            'transfer_gap': gap,\n            'transfer_efficiency': (real_avg / sim_avg) if sim_avg != 0 else 0\n        }\n\n    def plot_transfer_results(self):\n        \"\"\"Plot transfer learning results\"\"\"\n        import matplotlib.pyplot as plt\n\n        episodes = range(len(self.transfer_gap))\n\n        plt.figure(figsize=(12, 4))\n\n        plt.subplot(1, 3, 1)\n        plt.plot(episodes, self.sim_performance, label='Simulation')\n        plt.plot(episodes, self.real_performance, label='Real World')\n        plt.title('Performance Comparison')\n        plt.xlabel('Episode')\n        plt.ylabel('Reward')\n        plt.legend()\n\n        plt.subplot(1, 3, 2)\n        plt.plot(episodes, self.transfer_gap)\n        plt.title('Transfer Gap')\n        plt.xlabel('Episode')\n        plt.ylabel('Gap')\n\n        plt.subplot(1, 3, 3)\n        transfer_efficiency = [(r/s) if s != 0 else 0 for s, r in zip(self.sim_performance, self.real_performance)]\n        plt.plot(episodes, transfer_efficiency)\n        plt.title('Transfer Efficiency')\n        plt.xlabel('Episode')\n        plt.ylabel('Efficiency')\n\n        plt.tight_layout()\n        plt.show()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"exercise-tasks",children:"Exercise Tasks"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Implement domain randomization in your Isaac Sim environment"}),"\n",(0,i.jsx)(n.li,{children:"Create a domain adaptation network to bridge sim and real domains"}),"\n",(0,i.jsx)(n.li,{children:"Set up a transfer learning pipeline with progressive randomization"}),"\n",(0,i.jsx)(n.li,{children:"Implement system identification to learn sim-to-real dynamics"}),"\n",(0,i.jsx)(n.li,{children:"Test your trained simulation model on real hardware (or realistic simulation)"}),"\n",(0,i.jsx)(n.li,{children:"Evaluate and compare performance between simulation and reality"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Poor transfer performance"}),": Increase domain randomization range"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Training instability"}),": Reduce learning rate during fine-tuning"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor differences"}),": Implement sensor calibration and preprocessing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuator delays"}),": Account for real-world timing differences"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"In this lab, you learned techniques for transferring AI models from simulation to real robots. You implemented domain randomization, domain adaptation, and system identification methods to bridge the reality gap. These techniques are crucial for deploying simulation-trained models in real-world robotic applications."})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},8453(e,n,a){a.d(n,{R:()=>s,x:()=>o});var i=a(6540);const r={},t=i.createContext(r);function s(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);