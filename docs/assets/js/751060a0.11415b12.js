"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[9333],{2152:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>t,metadata:()=>s,toc:()=>d});var i=a(4848),r=a(8453);const t={},o="Simulation-to-Reality (Sim2Real)",s={id:"modules/ai-robot-brain/sim2real",title:"Simulation-to-Reality (Sim2Real)",description:"Overview",source:"@site/docs/modules/ai-robot-brain/sim2real.md",sourceDirName:"modules/ai-robot-brain",slug:"/modules/ai-robot-brain/sim2real",permalink:"/hackathon-ai-book/modules/ai-robot-brain/sim2real",draft:!1,unlisted:!1,editUrl:"https://github.com/sanilahmed/hackathon-ai-book/tree/main/docs/modules/ai-robot-brain/sim2real.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"AI-Robot Brain References",permalink:"/hackathon-ai-book/modules/ai-robot-brain/references"},next:{title:"Module 4: Vision-Language-Action (VLA) System",permalink:"/hackathon-ai-book/modules/vla-system/"}},l={},d=[{value:"Overview",id:"overview",level:2},{value:"The Sim2Real Problem",id:"the-sim2real-problem",level:2},{value:"Domain Gap Challenges",id:"domain-gap-challenges",level:3},{value:"Isaac Sim2Real Solutions",id:"isaac-sim2real-solutions",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Randomization Techniques",id:"randomization-techniques",level:3},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"System Identification",id:"system-identification",level:2},{value:"Real Robot Parameter Estimation",id:"real-robot-parameter-estimation",level:3},{value:"Dynamic Parameter Identification",id:"dynamic-parameter-identification",level:3},{value:"Adaptive Control",id:"adaptive-control",level:2},{value:"Online Adaptation",id:"online-adaptation",level:3},{value:"Model Reference Adaptive Control (MRAC)",id:"model-reference-adaptive-control-mrac",level:3},{value:"Robust Control Design",id:"robust-control-design",level:2},{value:"H-infinity Control",id:"h-infinity-control",level:3},{value:"Isaac Sim2Real Tools",id:"isaac-sim2real-tools",level:2},{value:"Isaac Sim Domain Randomization",id:"isaac-sim-domain-randomization",level:3},{value:"Isaac Lab Sim2Real Components",id:"isaac-lab-sim2real-components",level:3},{value:"Transfer Learning Strategies",id:"transfer-learning-strategies",level:2},{value:"Progressive Domain Transfer",id:"progressive-domain-transfer",level:3},{value:"Meta-Learning for Sim2Real",id:"meta-learning-for-sim2real",level:3},{value:"Validation and Testing",id:"validation-and-testing",level:2},{value:"Sim2Real Performance Metrics",id:"sim2real-performance-metrics",level:3},{value:"Real-World Deployment",id:"real-world-deployment",level:2},{value:"Deployment Pipeline",id:"deployment-pipeline",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Sim2Real Transfer Issues",id:"sim2real-transfer-issues",level:3}];function m(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"simulation-to-reality-sim2real",children:"Simulation-to-Reality (Sim2Real)"}),"\n",(0,i.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(e.p,{children:"Simulation-to-Reality (Sim2Real) is a critical component in robotics that enables transferring policies and behaviors learned in simulation to real-world robots. This section covers techniques, challenges, and best practices for achieving successful Sim2Real transfer with humanoid robots using NVIDIA Isaac."}),"\n",(0,i.jsx)(e.h2,{id:"the-sim2real-problem",children:"The Sim2Real Problem"}),"\n",(0,i.jsx)(e.h3,{id:"domain-gap-challenges",children:"Domain Gap Challenges"}),"\n",(0,i.jsx)(e.p,{children:'The primary challenge in Sim2Real transfer is the "domain gap" between simulation and reality:'}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Dynamics Mismatch"}),": Differences in friction, mass, and actuator dynamics"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensor Noise"}),": Real sensors have noise, latency, and imperfections"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Modeling Errors"}),": Inaccuracies in simulating real-world physics"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Environmental Factors"}),": Lighting, texture, and environmental conditions"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"isaac-sim2real-solutions",children:"Isaac Sim2Real Solutions"}),"\n",(0,i.jsx)(e.p,{children:"NVIDIA Isaac provides several tools to address these challenges:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Domain Randomization"}),": Randomizing simulation parameters"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"System Identification"}),": Calibrating simulation to reality"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Adaptive Control"}),": Online adaptation during deployment"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Robust Control"}),": Controllers that handle uncertainties"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,i.jsx)(e.h3,{id:"randomization-techniques",children:"Randomization Techniques"}),"\n",(0,i.jsx)(e.p,{children:"Domain randomization is a key technique for making policies robust to domain gaps:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Domain randomization implementation in Isaac\nimport numpy as np\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.materials import PhysicsMaterial\n\nclass DomainRandomizer:\n    def __init__(self, env_cfg):\n        self.env_cfg = env_cfg\n        self.randomization_ranges = {\n            'mass_ratio': [0.8, 1.2],\n            'friction': [0.5, 1.5],\n            'restitution': [0.0, 0.2],\n            'damping_ratio': [0.8, 1.2],\n            'actuator_strength': [0.8, 1.2],\n            'sensor_noise': [0.0, 0.05],\n            'latency': [0.0, 0.02],\n        }\n\n    def randomize_environment(self, env_id):\n        \"\"\"Randomize environment parameters for domain randomization.\"\"\"\n        # Randomize robot mass\n        mass_ratio = np.random.uniform(\n            self.randomization_ranges['mass_ratio'][0],\n            self.randomization_ranges['mass_ratio'][1]\n        )\n        self.apply_mass_randomization(env_id, mass_ratio)\n\n        # Randomize friction\n        friction = np.random.uniform(\n            self.randomization_ranges['friction'][0],\n            self.randomization_ranges['friction'][1]\n        )\n        self.apply_friction_randomization(env_id, friction)\n\n        # Randomize actuator strength\n        strength = np.random.uniform(\n            self.randomization_ranges['actuator_strength'][0],\n            self.randomization_ranges['actuator_strength'][1]\n        )\n        self.apply_actuator_randomization(env_id, strength)\n\n    def apply_mass_randomization(self, env_id, ratio):\n        \"\"\"Apply mass randomization to robot links.\"\"\"\n        # Implementation to modify mass properties\n        pass\n\n    def apply_friction_randomization(self, env_id, friction):\n        \"\"\"Apply friction randomization to contact materials.\"\"\"\n        # Implementation to modify friction coefficients\n        pass\n\n    def apply_actuator_randomization(self, env_id, strength):\n        \"\"\"Apply actuator strength randomization.\"\"\"\n        # Implementation to modify actuator parameters\n        pass\n"})}),"\n",(0,i.jsx)(e.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Visual domain randomization for perception systems\nclass VisualDomainRandomizer:\n    def __init__(self):\n        self.lighting_params = {\n            'intensity_range': [100, 1000],\n            'color_temperature_range': [3000, 8000],\n            'position_jitter': 0.5\n        }\n\n        self.material_params = {\n            'albedo_range': [0.1, 1.0],\n            'roughness_range': [0.0, 1.0],\n            'metallic_range': [0.0, 1.0]\n        }\n\n    def randomize_lighting(self, env_id):\n        \"\"\"Randomize lighting conditions.\"\"\"\n        intensity = np.random.uniform(\n            self.lighting_params['intensity_range'][0],\n            self.lighting_params['intensity_range'][1]\n        )\n\n        color_temp = np.random.uniform(\n            self.lighting_params['color_temperature_range'][0],\n            self.lighting_params['color_temperature_range'][1]\n        )\n\n        # Apply lighting changes\n        self.set_light_intensity(env_id, intensity)\n        self.set_light_color_temperature(env_id, color_temp)\n\n    def randomize_materials(self, env_id):\n        \"\"\"Randomize material properties.\"\"\"\n        for material in self.get_scene_materials(env_id):\n            albedo = np.random.uniform(\n                self.material_params['albedo_range'][0],\n                self.material_params['albedo_range'][1]\n            )\n\n            roughness = np.random.uniform(\n                self.material_params['roughness_range'][0],\n                self.material_params['roughness_range'][1]\n            )\n\n            # Apply material changes\n            self.set_material_albedo(material, albedo)\n            self.set_material_roughness(material, roughness)\n"})}),"\n",(0,i.jsx)(e.h2,{id:"system-identification",children:"System Identification"}),"\n",(0,i.jsx)(e.h3,{id:"real-robot-parameter-estimation",children:"Real Robot Parameter Estimation"}),"\n",(0,i.jsx)(e.p,{children:"System identification is crucial for calibrating simulation to match real robot behavior:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# System identification for humanoid robot\nimport numpy as np\nfrom scipy.optimize import minimize\nimport torch\n\nclass SystemIdentifier:\n    def __init__(self, robot_model):\n        self.robot = robot_model\n        self.sim_model = self.load_simulation_model()\n        self.real_data_buffer = []\n\n    def collect_excitation_data(self):\n        """Collect data for system identification."""\n        # Apply known inputs to real robot and measure outputs\n        input_signals = self.generate_excitation_signals()\n\n        for input_signal in input_signals:\n            # Apply input to real robot\n            real_output = self.apply_input_and_measure(input_signal)\n\n            # Apply same input to simulation\n            sim_output = self.sim_model.simulate(input_signal)\n\n            # Store data pair\n            self.real_data_buffer.append((input_signal, real_output, sim_output))\n\n    def estimate_parameters(self):\n        """Estimate robot parameters using collected data."""\n        # Define objective function to minimize sim-real difference\n        def objective(params):\n            total_error = 0\n\n            # Update simulation with current parameters\n            self.sim_model.update_parameters(params)\n\n            for input_signal, real_output, _ in self.real_data_buffer:\n                sim_output = self.sim_model.simulate(input_signal)\n                error = np.sum((real_output - sim_output) ** 2)\n                total_error += error\n\n            return total_error\n\n        # Initial parameter guess\n        initial_params = self.get_initial_parameter_guess()\n\n        # Optimize parameters\n        result = minimize(objective, initial_params, method=\'L-BFGS-B\')\n\n        return result.x\n\n    def get_identified_parameters(self):\n        """Get identified parameters for simulation calibration."""\n        return {\n            \'mass\': self.estimate_mass_properties(),\n            \'inertia\': self.estimate_inertia_properties(),\n            \'friction\': self.estimate_friction_parameters(),\n            \'actuator_dynamics\': self.estimate_actuator_dynamics(),\n            \'sensor_bias\': self.estimate_sensor_bias()\n        }\n'})}),"\n",(0,i.jsx)(e.h3,{id:"dynamic-parameter-identification",children:"Dynamic Parameter Identification"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Dynamic parameter identification using least squares\nclass DynamicParameterIdentifier:\n    def __init__(self):\n        self.regressor_matrix = []\n        self.torque_measurements = []\n\n    def generate_regression_data(self, joint_positions, joint_velocities, joint_accelerations, torques):\n        """Generate regression data for dynamic parameter identification."""\n        for i in range(len(joint_positions)):\n            # Create regressor vector for rigid body dynamics\n            regressor = self.create_dynamic_regressor(\n                joint_positions[i],\n                joint_velocities[i],\n                joint_accelerations[i]\n            )\n\n            self.regressor_matrix.append(regressor)\n            self.torque_measurements.append(torques[i])\n\n    def create_dynamic_regressor(self, q, q_dot, q_ddot):\n        """Create regressor vector for rigid body dynamics."""\n        # For a humanoid with n joints, regressor includes:\n        # - Gravity terms: sin(q), cos(q)\n        # - Coriolis terms: q_dot * q_dot, sin(q) * q_dot, cos(q) * q_dot\n        # - Inertial terms: q_ddot\n\n        n = len(q)  # number of joints\n        regressor_size = self.calculate_regressor_size(n)\n        regressor = np.zeros(regressor_size)\n\n        # Fill regressor with dynamic terms\n        idx = 0\n\n        # Gravity terms\n        for i in range(n):\n            regressor[idx] = np.sin(q[i])\n            idx += 1\n            regressor[idx] = np.cos(q[i])\n            idx += 1\n\n        # Coriolis terms\n        for i in range(n):\n            for j in range(n):\n                regressor[idx] = q_dot[i] * q_dot[j]\n                idx += 1\n\n        # Inertial terms\n        for i in range(n):\n            regressor[idx] = q_ddot[i]\n            idx += 1\n\n        return regressor\n\n    def identify_parameters(self):\n        """Identify dynamic parameters using least squares."""\n        Y = np.array(self.torque_measurements)  # Torque measurements\n        Phi = np.array(self.regressor_matrix)   # Regressor matrix\n\n        # Solve: Y = Phi * Theta\n        # Theta = (Phi^T * Phi)^(-1) * Phi^T * Y\n        try:\n            params = np.linalg.solve(Phi.T @ Phi, Phi.T @ Y)\n        except np.linalg.LinAlgError:\n            # Use pseudo-inverse if matrix is singular\n            params = np.linalg.pinv(Phi) @ Y\n\n        return params\n'})}),"\n",(0,i.jsx)(e.h2,{id:"adaptive-control",children:"Adaptive Control"}),"\n",(0,i.jsx)(e.h3,{id:"online-adaptation",children:"Online Adaptation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Online adaptation during real-world deployment\nimport torch\nimport numpy as np\n\nclass OnlineAdaptation:\n    def __init__(self, policy_network, adaptation_rate=0.01):\n        self.policy_network = policy_network\n        self.adaptation_rate = adaptation_rate\n        self.adaptation_network = self.build_adaptation_network()\n        self.performance_buffer = []\n\n    def adapt_policy(self, state, action, reward, next_state, real_observation):\n        """Adapt policy based on real-world observations."""\n        # Compute prediction error\n        predicted_obs = self.policy_network.predict(state, action)\n        prediction_error = real_observation - predicted_obs\n\n        # Store performance data\n        self.performance_buffer.append({\n            \'state\': state,\n            \'action\': action,\n            \'error\': prediction_error,\n            \'reward\': reward\n        })\n\n        # Adapt if sufficient data collected\n        if len(self.performance_buffer) > 100:\n            self.update_policy_with_adaptation()\n            self.performance_buffer = []  # Reset buffer\n\n    def build_adaptation_network(self):\n        """Build network for computing adaptation parameters."""\n        return torch.nn.Sequential(\n            torch.nn.Linear(24, 64),  # state + action\n            torch.nn.ReLU(),\n            torch.nn.Linear(64, 32),\n            torch.nn.ReLU(),\n            torch.nn.Linear(32, 16)   # adaptation parameters\n        )\n\n    def update_policy_with_adaptation(self):\n        """Update policy using adaptation network."""\n        # Compute adaptation based on performance buffer\n        adaptation_params = self.compute_adaptation()\n\n        # Apply adaptation to policy network\n        self.apply_adaptation_to_policy(adaptation_params)\n\n    def compute_adaptation(self):\n        """Compute adaptation parameters from performance data."""\n        states = torch.FloatTensor([d[\'state\'] for d in self.performance_buffer])\n        actions = torch.FloatTensor([d[\'action\'] for d in self.performance_buffer])\n        errors = torch.FloatTensor([d[\'error\'] for d in self.performance_buffer])\n\n        # Use adaptation network to compute parameters\n        adaptation_input = torch.cat([states, actions], dim=1)\n        adaptation_params = self.adaptation_network(adaptation_input)\n\n        return torch.mean(adaptation_params, dim=0)\n'})}),"\n",(0,i.jsx)(e.h3,{id:"model-reference-adaptive-control-mrac",children:"Model Reference Adaptive Control (MRAC)"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Model Reference Adaptive Control for humanoid\nclass MRACController:\n    def __init__(self, reference_model, robot_model):\n        self.reference_model = reference_model\n        self.robot_model = robot_model\n        self.adaptive_gains = np.zeros(robot_model.n_joints)\n        self.integration_gain = 10.0\n\n    def compute_control(self, state, reference_state):\n        """Compute control using MRAC approach."""\n        # Tracking error\n        tracking_error = reference_state - state\n\n        # Reference model control\n        reference_control = self.reference_model.compute_control(\n            reference_state\n        )\n\n        # Adaptive control term\n        adaptive_control = self.compute_adaptive_control(\n            tracking_error\n        )\n\n        # Total control\n        total_control = reference_control + adaptive_control\n\n        return total_control\n\n    def compute_adaptive_control(self, tracking_error):\n        """Compute adaptive control term."""\n        # Update adaptive parameters using gradient descent\n        for i in range(len(self.adaptive_gains)):\n            self.adaptive_gains[i] += (\n                self.integration_gain *\n                tracking_error[i] *\n                abs(tracking_error[i])\n            )\n\n        # Apply adaptive gains to error\n        adaptive_control = self.adaptive_gains * tracking_error\n\n        return adaptive_control\n'})}),"\n",(0,i.jsx)(e.h2,{id:"robust-control-design",children:"Robust Control Design"}),"\n",(0,i.jsx)(e.h3,{id:"h-infinity-control",children:"H-infinity Control"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Robust H-infinity control for humanoid\nimport numpy as np\nfrom scipy.linalg import solve_continuous_are\n\nclass HInfinityController:\n    def __init__(self, nominal_model, uncertainty_bound):\n        self.nominal_model = nominal_model\n        self.uncertainty_bound = uncertainty_bound\n        self.controller_gain = self.synthesize_controller()\n\n    def synthesize_controller(self):\n        """Synthesize H-infinity controller."""\n        # System matrices: dx/dt = Ax + B1*w + B2*u\n        # z = C1*x + D11*w + D12*u\n        # y = C2*x + D21*w + D22*u\n\n        A, B1, B2, C1, C2, D11, D12, D21, D22 = self.get_system_matrices()\n\n        # Synthesize H-infinity controller\n        # This is a simplified version - in practice, use specialized tools\n        gamma = 1.0 + self.uncertainty_bound  # Performance bound\n\n        # Solve H-infinity Riccati equations\n        # (Simplified implementation)\n        P = solve_continuous_are(A, B2, C1.T @ C1, B2.T @ B2 + gamma**2 * np.eye(B2.shape[1]))\n\n        # Controller gain\n        K = np.linalg.inv(B2.T @ B2 + gamma**2 * np.eye(B2.shape[1])) @ B2.T @ P\n\n        return K\n\n    def get_system_matrices(self):\n        """Get linearized system matrices around operating point."""\n        # Linearize nominal model\n        A = self.nominal_model.get_jacobian_state()\n        B2 = self.nominal_model.get_jacobian_input()\n\n        # For simplicity, assume other matrices\n        B1 = 0.1 * np.eye(A.shape[0])  # Uncertainty input\n        C1 = np.eye(A.shape[0])        # Performance output\n        C2 = np.eye(A.shape[0])        # Measurement output\n        D11 = 0.1 * np.eye(B1.shape[1])\n        D12 = 0.1 * np.eye(B2.shape[1])\n        D21 = 0.1 * np.eye(B1.shape[1])\n        D22 = 0.1 * np.eye(B2.shape[1])\n\n        return A, B1, B2, C1, C2, D11, D12, D21, D22\n\n    def compute_robust_control(self, state, disturbance_estimate):\n        """Compute robust control with disturbance rejection."""\n        # Nominal control\n        nominal_control = -self.controller_gain @ state\n\n        # Disturbance compensation\n        disturbance_compensation = self.estimate_disturbance_rejection(\n            disturbance_estimate\n        )\n\n        return nominal_control + disturbance_compensation\n'})}),"\n",(0,i.jsx)(e.h2,{id:"isaac-sim2real-tools",children:"Isaac Sim2Real Tools"}),"\n",(0,i.jsx)(e.h3,{id:"isaac-sim-domain-randomization",children:"Isaac Sim Domain Randomization"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Using Isaac Sim\'s built-in domain randomization\nfrom omni.isaac.orbit.assets import AssetBaseCfg\nfrom omni.isaac.orbit.managers import SceneEntityCfg\nimport omni.isaac.orbit.sim as sim_utils\n\ndef setup_isaac_domain_randomization():\n    """Setup Isaac Sim domain randomization."""\n\n    # Physics randomization\n    physics_randomization = {\n        "mass": {"range": [0.8, 1.2], "operation": "scale"},\n        "friction": {"range": [0.5, 1.5], "operation": "scale"},\n        "restitution": {"range": [0.0, 0.2], "operation": "add"},\n        "damping": {"range": [0.8, 1.2], "operation": "scale"},\n    }\n\n    # Visual randomization\n    visual_randomization = {\n        "lighting": {\n            "intensity": {"range": [100, 1000], "operation": "scale"},\n            "color": {"range": [0.0, 1.0], "operation": "add"},\n        },\n        "materials": {\n            "albedo": {"range": [0.1, 1.0], "operation": "scale"},\n            "roughness": {"range": [0.0, 1.0], "operation": "add"},\n        }\n    }\n\n    # Sensor randomization\n    sensor_randomization = {\n        "noise": {"range": [0.0, 0.05], "operation": "add"},\n        "latency": {"range": [0.0, 0.02], "operation": "add"},\n        "delay": {"range": [0.0, 0.01], "operation": "add"},\n    }\n\n    return physics_randomization, visual_randomization, sensor_randomization\n\n# Environment configuration with domain randomization\nclass IsaacSim2RealEnvCfg:\n    # Physics randomization\n    physics_randomization = {\n        "enabled": True,\n        "randomization_params": setup_isaac_domain_randomization()[0]\n    }\n\n    # Visual randomization\n    visual_randomization = {\n        "enabled": True,\n        "randomization_params": setup_isaac_domain_randomization()[1]\n    }\n\n    # Sensor randomization\n    sensor_randomization = {\n        "enabled": True,\n        "randomization_params": setup_isaac_domain_randomization()[2]\n    }\n'})}),"\n",(0,i.jsx)(e.h3,{id:"isaac-lab-sim2real-components",children:"Isaac Lab Sim2Real Components"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Isaac Lab Sim2Real components\nfrom omni.isaac.orbit.assets import RigidObjectCfg, AssetBaseCfg\nfrom omni.isaac.orbit.managers import SceneEntityCfg\nimport omni.isaac.orbit.sim as sim_utils\n\nclass IsaacSim2RealComponents:\n    def __init__(self):\n        self.domain_randomizer = self.setup_domain_randomization()\n        self.system_id = SystemIdentifier()\n        self.adaptation_module = OnlineAdaptation()\n\n    def setup_domain_randomization(self):\n        """Setup Isaac Lab domain randomization."""\n        # Create domain randomization configuration\n        domain_randomization_cfg = {\n            "num_envs": 4096,\n            "env_spacing": 2.5,\n            "randomize_physics": True,\n            "randomize_visual": True,\n            "randomize_sensors": True,\n            "randomization_intervals": {\n                "physics": 100,  # Randomize every 100 episodes\n                "visual": 10,    # Randomize every 10 episodes\n                "sensors": 5,    # Randomize every 5 episodes\n            }\n        }\n        return domain_randomization_cfg\n\n    def setup_calibration_environment(self):\n        """Setup environment for system identification."""\n        # Create calibration-specific environment\n        calibration_env_cfg = {\n            "scene": SceneEntityCfg(\n                num_envs=1,  # Single environment for calibration\n                env_spacing=0.0,  # No spacing needed\n            ),\n            "robot": AssetBaseCfg(\n                prim_path="{ENV_REGEX_NS}/Robot",\n                spawn=sim_utils.UsdFileCfg(\n                    usd_path="/path/to/humanoid_robot.usd",\n                    scale=(1.0, 1.0, 1.0),\n                ),\n                init_state={\n                    "joint_pos": {".*": 0.0},\n                    "joint_vel": {".*": 0.0},\n                },\n            ),\n            # Add calibration-specific sensors\n            "calibration_sensors": {\n                "force_torque": True,\n                "high_freq_imu": True,\n                "precise_encoders": True,\n            }\n        }\n        return calibration_env_cfg\n'})}),"\n",(0,i.jsx)(e.h2,{id:"transfer-learning-strategies",children:"Transfer Learning Strategies"}),"\n",(0,i.jsx)(e.h3,{id:"progressive-domain-transfer",children:"Progressive Domain Transfer"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Progressive domain transfer from simple to complex\nclass ProgressiveTransfer:\n    def __init__(self):\n        self.transfer_levels = [\n            'simple_shapes',\n            'textured_shapes',\n            'realistic_objects',\n            'complex_environments',\n            'real_world'\n        ]\n        self.current_level = 0\n\n    def train_progressive(self):\n        \"\"\"Train progressively across domain levels.\"\"\"\n        for level_idx, level in enumerate(self.transfer_levels):\n            print(f\"Training on domain level: {level}\")\n\n            # Create environment for current level\n            env = self.create_level_environment(level)\n\n            # If not first level, adapt from previous level\n            if level_idx > 0:\n                self.adapt_from_previous_level(env)\n\n            # Train on current level\n            self.train_on_level(env, level)\n\n            # Evaluate transfer to next level\n            if level_idx < len(self.transfer_levels) - 1:\n                next_level = self.transfer_levels[level_idx + 1]\n                performance = self.evaluate_transfer(level, next_level)\n\n                if performance > 0.8:  # 80% success threshold\n                    self.current_level = level_idx + 1\n                else:\n                    # Retrain with more randomization\n                    self.increase_randomization(level)\n\n    def create_level_environment(self, level):\n        \"\"\"Create environment for specific transfer level.\"\"\"\n        if level == 'simple_shapes':\n            return self.create_simple_shapes_env()\n        elif level == 'textured_shapes':\n            return self.create_textured_shapes_env()\n        elif level == 'realistic_objects':\n            return self.create_realistic_objects_env()\n        elif level == 'complex_environments':\n            return self.create_complex_envs_env()\n        else:  # real_world\n            return self.create_real_world_env()\n"})}),"\n",(0,i.jsx)(e.h3,{id:"meta-learning-for-sim2real",children:"Meta-Learning for Sim2Real"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Meta-learning approach for rapid Sim2Real adaptation\nimport torch\nimport torch.nn as nn\n\nclass MetaLearningSim2Real(nn.Module):\n    def __init__(self, policy_network, meta_learning_rate=0.001):\n        super().__init__()\n        self.policy = policy_network\n        self.meta_lr = meta_learning_rate\n        self.meta_network = self.create_meta_network()\n\n    def create_meta_network(self):\n        """Create meta-learning network."""\n        return nn.Sequential(\n            nn.Linear(64, 32),  # Adaptation parameters\n            nn.ReLU(),\n            nn.Linear(32, 16),\n            nn.ReLU(),\n            nn.Linear(16, 8)    # Meta-gradients\n        )\n\n    def forward(self, state, adaptation_params=None):\n        """Forward pass with optional adaptation."""\n        if adaptation_params is not None:\n            # Apply adaptation to policy\n            adapted_policy = self.adapt_policy(adaptation_params)\n            return adapted_policy(state)\n        else:\n            return self.policy(state)\n\n    def adapt_policy(self, adaptation_params):\n        """Adapt policy parameters."""\n        # This is a simplified adaptation approach\n        # In practice, use MAML or Reptile algorithms\n        adapted_policy = copy.deepcopy(self.policy)\n\n        # Apply adaptation to policy parameters\n        for param, adapt_param in zip(\n            adapted_policy.parameters(),\n            adaptation_params\n        ):\n            param.data += self.meta_lr * adapt_param\n\n        return adapted_policy\n\n    def meta_update(self, sim_batch, real_batch):\n        """Update meta-learning parameters."""\n        # Train on simulation batch\n        sim_loss = self.compute_loss(sim_batch)\n\n        # Compute meta-gradient on real batch\n        real_loss = self.compute_loss(real_batch)\n\n        # Meta-update\n        meta_grad = torch.autograd.grad(real_loss, self.parameters())\n\n        return sim_loss, meta_grad\n'})}),"\n",(0,i.jsx)(e.h2,{id:"validation-and-testing",children:"Validation and Testing"}),"\n",(0,i.jsx)(e.h3,{id:"sim2real-performance-metrics",children:"Sim2Real Performance Metrics"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Sim2Real performance evaluation\nclass Sim2RealEvaluator:\n    def __init__(self):\n        self.metrics = {\n            'sim_real_correlation': [],\n            'transfer_success_rate': [],\n            'performance_degradation': [],\n            'adaptation_speed': [],\n            'robustness_score': []\n        }\n\n    def evaluate_transfer(self, sim_policy, real_robot):\n        \"\"\"Evaluate Sim2Real transfer performance.\"\"\"\n        # Test policy on simulation\n        sim_performance = self.evaluate_on_simulation(sim_policy)\n\n        # Transfer to real robot\n        real_performance = self.evaluate_on_real_robot(sim_policy, real_robot)\n\n        # Calculate metrics\n        correlation = self.compute_sim_real_correlation(sim_performance, real_performance)\n        success_rate = self.compute_transfer_success_rate(real_performance)\n        degradation = self.compute_performance_degradation(sim_performance, real_performance)\n\n        return {\n            'correlation': correlation,\n            'success_rate': success_rate,\n            'degradation': degradation\n        }\n\n    def compute_sim_real_correlation(self, sim_data, real_data):\n        \"\"\"Compute correlation between sim and real performance.\"\"\"\n        # Calculate Pearson correlation coefficient\n        sim_rewards = [d['reward'] for d in sim_data]\n        real_rewards = [d['reward'] for d in real_data]\n\n        correlation_matrix = np.corrcoef(sim_rewards, real_rewards)\n        return correlation_matrix[0, 1]\n\n    def compute_performance_degradation(self, sim_perf, real_perf):\n        \"\"\"Compute performance degradation from sim to real.\"\"\"\n        return (sim_perf['mean_reward'] - real_perf['mean_reward']) / sim_perf['mean_reward']\n\n    def compute_robustness_score(self, policy, disturbance_levels):\n        \"\"\"Compute robustness to disturbances.\"\"\"\n        scores = []\n        for level in disturbance_levels:\n            disturbed_performance = self.evaluate_with_disturbance(policy, level)\n            scores.append(disturbed_performance['success_rate'])\n\n        return np.mean(scores)\n"})}),"\n",(0,i.jsx)(e.h2,{id:"real-world-deployment",children:"Real-World Deployment"}),"\n",(0,i.jsx)(e.h3,{id:"deployment-pipeline",children:"Deployment Pipeline"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Sim2Real deployment pipeline\nclass Sim2RealDeployment:\n    def __init__(self, trained_policy, robot_interface):\n        self.policy = trained_policy\n        self.robot = robot_interface\n        self.calibration_data = None\n        self.adaptation_module = OnlineAdaptation(policy)\n\n    def deploy_policy(self):\n        """Deploy policy to real robot with safety measures."""\n        # 1. Safety checks\n        if not self.pre_deployment_safety_check():\n            raise RuntimeError("Safety check failed")\n\n        # 2. Initial calibration\n        self.calibrate_robot()\n\n        # 3. Safe deployment with monitoring\n        self.run_with_monitoring()\n\n    def pre_deployment_safety_check(self):\n        """Perform safety checks before deployment."""\n        checks = [\n            self.check_robot_hardware_status(),\n            self.verify_communication_links(),\n            self.validate_policy_bounds(),\n            self.confirm_safety_zones(),\n            self.test_emergency_stop()\n        ]\n\n        return all(checks)\n\n    def calibrate_robot(self):\n        """Calibrate robot before deployment."""\n        # Collect calibration data\n        self.calibration_data = self.collect_calibration_data()\n\n        # Adapt policy based on calibration\n        adapted_policy = self.adapt_policy_to_robot()\n\n        return adapted_policy\n\n    def run_with_monitoring(self):\n        """Run policy with continuous monitoring."""\n        safety_monitor = SafetyMonitor(self.robot)\n\n        try:\n            while not safety_monitor.emergency_stop_triggered():\n                # Get current state\n                state = self.robot.get_state()\n\n                # Get action from policy\n                action = self.policy.get_action(state)\n\n                # Apply safety limits\n                safe_action = self.apply_safety_limits(action)\n\n                # Execute action\n                self.robot.execute_action(safe_action)\n\n                # Monitor for adaptation opportunities\n                self.adaptation_module.adapt_if_needed(state, action)\n\n        except Exception as e:\n            print(f"Deployment error: {e}")\n            self.robot.emergency_stop()\n'})}),"\n",(0,i.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,i.jsx)(e.h3,{id:"sim2real-transfer-issues",children:"Sim2Real Transfer Issues"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Large Performance Gap"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Increase domain randomization range"}),"\n",(0,i.jsx)(e.li,{children:"Add more realistic sensor noise models"}),"\n",(0,i.jsx)(e.li,{children:"Use system identification to calibrate simulation"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Unstable Real-World Behavior"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Add robust control components"}),"\n",(0,i.jsx)(e.li,{children:"Reduce control gains for safety"}),"\n",(0,i.jsx)(e.li,{children:"Implement safety constraints"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Poor Adaptation Speed"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Increase adaptation learning rate"}),"\n",(0,i.jsx)(e.li,{children:"Use more informative training data"}),"\n",(0,i.jsx)(e.li,{children:"Implement meta-learning approaches"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Sensor-Action Delay Issues"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Model sensor delays in simulation"}),"\n",(0,i.jsx)(e.li,{children:"Use prediction-based control"}),"\n",(0,i.jsx)(e.li,{children:"Implement compensation algorithms"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.a,{href:"/hackathon-ai-book/modules/ai-robot-brain/ai-integration",children:"Next: AI Integration"})," | ",(0,i.jsx)(e.a,{href:"/hackathon-ai-book/modules/ai-robot-brain/reinforcement-learning",children:"Previous: Reinforcement Learning"})]})]})}function c(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(m,{...n})}):m(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>o,x:()=>s});var i=a(6540);const r={},t=i.createContext(r);function o(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);