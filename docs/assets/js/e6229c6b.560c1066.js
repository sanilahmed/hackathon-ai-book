"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[7238],{7041:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>l});var t=o(4848),i=o(8453);const r={},a="Reinforcement Learning",s={id:"modules/ai-robot-brain/reinforcement-learning",title:"Reinforcement Learning",description:"This page covers navigation stack implementation.",source:"@site/docs/modules/ai-robot-brain/reinforcement-learning.md",sourceDirName:"modules/ai-robot-brain",slug:"/modules/ai-robot-brain/reinforcement-learning",permalink:"/hackathon-ai-book/modules/ai-robot-brain/reinforcement-learning",draft:!1,unlisted:!1,editUrl:"https://github.com/your-org/physical-ai-book/tree/main/docs/modules/ai-robot-brain/reinforcement-learning.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Planning and Control",permalink:"/hackathon-ai-book/modules/ai-robot-brain/planning-control"},next:{title:"Lab 3.1: Isaac Navigation",permalink:"/hackathon-ai-book/modules/lab-exercises/lab-3-1-isaac-navigation"}},c={},l=[];function m(n){const e={h1:"h1",p:"p",...(0,i.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"reinforcement-learning",children:"Reinforcement Learning"}),"\n",(0,t.jsx)(e.p,{children:"This page covers navigation stack implementation."})]})}function u(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(m,{...n})}):m(n)}},8453:(n,e,o)=>{o.d(e,{R:()=>a,x:()=>s});var t=o(6540);const i={},r=t.createContext(i);function a(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);