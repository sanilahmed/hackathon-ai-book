"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[9388],{7642:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>l,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>u});var s=n(4848),a=n(8453);const o={},l="VLA Fundamentals",i={id:"modules/vla-system/vla-fundamentals",title:"VLA Fundamentals",description:"This page covers the fundamentals of Vision-Language-Action systems.",source:"@site/docs/modules/vla-system/vla-fundamentals.md",sourceDirName:"modules/vla-system",slug:"/modules/vla-system/vla-fundamentals",permalink:"/hackathon-ai-book/modules/vla-system/vla-fundamentals",draft:!1,unlisted:!1,editUrl:"https://github.com/your-org/physical-ai-book/tree/main/docs/modules/vla-system/vla-fundamentals.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Module 4: Vision-Language-Action (VLA)",permalink:"/hackathon-ai-book/modules/vla-system/"},next:{title:"VLA Architecture",permalink:"/hackathon-ai-book/modules/vla-system/vla-architecture"}},r={},u=[];function c(e){const t={h1:"h1",p:"p",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"vla-fundamentals",children:"VLA Fundamentals"}),"\n",(0,s.jsx)(t.p,{children:"This page covers the fundamentals of Vision-Language-Action systems."})]})}function m(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>l,x:()=>i});var s=n(6540);const a={},o=s.createContext(a);function l(e){const t=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),s.createElement(o.Provider,{value:t},e.children)}}}]);