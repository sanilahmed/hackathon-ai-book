"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[1852],{4855:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>d});var a=t(4848),i=t(8453);const s={},r="Lab 3.5: Sim-to-Real Transfer",o={id:"modules/lab-exercises/lab-3-5-sim2real-transfer",title:"Lab 3.5: Sim-to-Real Transfer",description:"Overview",source:"@site/docs/modules/lab-exercises/lab-3-5-sim2real-transfer.md",sourceDirName:"modules/lab-exercises",slug:"/modules/lab-exercises/lab-3-5-sim2real-transfer",permalink:"/hackathon-ai-book/modules/lab-exercises/lab-3-5-sim2real-transfer",draft:!1,unlisted:!1,editUrl:"https://github.com/sanilahmed/hackathon-ai-book/tree/main/docs/modules/lab-exercises/lab-3-5-sim2real-transfer.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Lab 3.4: Isaac Sim Reinforcement Learning Systems",permalink:"/hackathon-ai-book/modules/lab-exercises/lab-3-4-reinforcement-learning"},next:{title:"AI-Robot Brain References",permalink:"/hackathon-ai-book/modules/ai-robot-brain/references"}},l={},d=[{value:"Overview",id:"overview",level:2},{value:"Objectives",id:"objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Duration",id:"duration",level:2},{value:"Exercise 1: Understanding the Reality Gap",id:"exercise-1-understanding-the-reality-gap",level:2},{value:"Step 1: Create a reality gap analysis environment",id:"step-1-create-a-reality-gap-analysis-environment",level:3},{value:"Exercise 2: Domain Randomization Implementation",id:"exercise-2-domain-randomization-implementation",level:2},{value:"Step 1: Create domain randomization system",id:"step-1-create-domain-randomization-system",level:3},{value:"Exercise 3: System Identification",id:"exercise-3-system-identification",level:2},{value:"Step 1: Create system identification tools",id:"step-1-create-system-identification-tools",level:3},{value:"Exercise 4: Model Adaptation and Fine-Tuning",id:"exercise-4-model-adaptation-and-fine-tuning",level:2},{value:"Step 1: Create model adaptation system",id:"step-1-create-model-adaptation-system",level:3},{value:"Exercise 5: Validation and Deployment",id:"exercise-5-validation-and-deployment",level:2},{value:"Step 1: Create validation and deployment tools",id:"step-1-create-validation-and-deployment-tools",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Extension Exercises",id:"extension-exercises",level:2},{value:"Summary",id:"summary",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"lab-35-sim-to-real-transfer",children:"Lab 3.5: Sim-to-Real Transfer"}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"In this lab, you will learn about sim-to-real transfer techniques for robotics applications. You'll explore domain randomization, system identification, model adaptation, and validation methods to bridge the gap between simulation and real-world robotics. This includes understanding the reality gap, implementing transfer learning techniques, and validating performance on physical robots."}),"\n",(0,a.jsx)(n.h2,{id:"objectives",children:"Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this lab, you will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Understand the challenges of sim-to-real transfer"}),"\n",(0,a.jsx)(n.li,{children:"Implement domain randomization techniques"}),"\n",(0,a.jsx)(n.li,{children:"Perform system identification for robot modeling"}),"\n",(0,a.jsx)(n.li,{children:"Apply model adaptation and fine-tuning methods"}),"\n",(0,a.jsx)(n.li,{children:"Validate performance in both simulation and reality"}),"\n",(0,a.jsx)(n.li,{children:"Implement safety measures for real-world deployment"}),"\n",(0,a.jsx)(n.li,{children:"Design experiments to evaluate transfer effectiveness"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Completion of Lab 3.1-3.4: Isaac Sim Setup, Perception, Planning/Control, and RL"}),"\n",(0,a.jsx)(n.li,{children:"Understanding of system identification concepts"}),"\n",(0,a.jsx)(n.li,{children:"Experience with reinforcement learning and domain randomization"}),"\n",(0,a.jsx)(n.li,{children:"Basic knowledge of control theory and robot dynamics"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"duration",children:"Duration"}),"\n",(0,a.jsx)(n.p,{children:"5-6 hours"}),"\n",(0,a.jsx)(n.h2,{id:"exercise-1-understanding-the-reality-gap",children:"Exercise 1: Understanding the Reality Gap"}),"\n",(0,a.jsx)(n.h3,{id:"step-1-create-a-reality-gap-analysis-environment",children:"Step 1: Create a reality gap analysis environment"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/isaac_sim_examples/reality_gap_analysis.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n# reality_gap_analysis.py\n"""Reality gap analysis for sim-to-real transfer."""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.distance import cdist\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport warnings\nwarnings.filterwarnings(\'ignore\')\n\nclass RealityGapAnalyzer:\n    """Analyze and quantify the reality gap between simulation and reality."""\n\n    def __init__(self):\n        self.simulation_data = []\n        self.real_data = []\n        self.gap_metrics = {}\n        self.transfer_functions = {}\n\n    def collect_simulation_data(self, num_samples=1000):\n        """Collect data from simulation environment."""\n        print("Collecting simulation data...")\n\n        # Simulate various robot behaviors in simulation\n        for i in range(num_samples):\n            # Generate random control inputs\n            control_input = np.random.uniform(-1, 1, size=6)  # 6 DoF control\n\n            # Simulate robot response in simulation (with idealized physics)\n            sim_state = self.simulate_robot_response(control_input)\n\n            self.simulation_data.append({\n                \'control_input\': control_input,\n                \'state\': sim_state,\n                \'timestamp\': i\n            })\n\n        print(f"Collected {len(self.simulation_data)} simulation samples")\n\n    def collect_real_data(self, num_samples=500):\n        """Collect data from real robot (simulated for this example)."""\n        print("Collecting real robot data...")\n\n        # In a real scenario, this would interface with the actual robot\n        # For simulation, we\'ll add realistic noise and dynamics differences\n        for i in range(num_samples):\n            # Use same control inputs as simulation for comparison\n            if i < len(self.simulation_data):\n                control_input = self.simulation_data[i][\'control_input\']\n            else:\n                control_input = np.random.uniform(-1, 1, size=6)\n\n            # Simulate real robot response (with realistic noise and dynamics)\n            real_state = self.simulate_real_robot_response(control_input)\n\n            self.real_data.append({\n                \'control_input\': control_input,\n                \'state\': real_state,\n                \'timestamp\': i\n            })\n\n        print(f"Collected {len(self.real_data)} real robot samples")\n\n    def simulate_robot_response(self, control_input):\n        """Simulate idealized robot response in simulation."""\n        # Simplified robot dynamics model\n        # In reality, this would be the simulation environment\n        dt = 0.01  # Time step\n\n        # Apply control input with idealized dynamics\n        position = control_input[:3] * dt * 0.5  # Position change\n        velocity = control_input[:3]  # Velocity\n        orientation = control_input[3:6] * dt * 0.1  # Orientation change\n\n        state = np.concatenate([position, velocity, orientation])\n        return state\n\n    def simulate_real_robot_response(self, control_input):\n        """Simulate realistic robot response with noise and dynamics differences."""\n        # Simulate real-world effects:\n        # 1. Sensor noise\n        # 2. Actuator delays\n        # 3. Unmodeled dynamics\n        # 4. Environmental factors\n\n        dt = 0.01  # Time step\n\n        # Start with ideal response\n        ideal_position = control_input[:3] * dt * 0.4  # Slightly different gain\n        ideal_velocity = control_input[:3] * 0.9  # Different velocity scaling\n        ideal_orientation = control_input[3:6] * dt * 0.08  # Different orientation scaling\n\n        # Add realistic noise\n        noise_level = 0.05\n        position_noise = np.random.normal(0, noise_level * 0.1, size=3)\n        velocity_noise = np.random.normal(0, noise_level * 0.05, size=3)\n        orientation_noise = np.random.normal(0, noise_level * 0.02, size=3)\n\n        # Add systematic differences\n        systematic_error = np.array([\n            control_input[0] * 0.02,  # Position bias\n            control_input[1] * 0.01,\n            control_input[2] * 0.015,\n            0, 0, 0  # No systematic error in velocity/orientation for simplicity\n        ])\n\n        state = np.concatenate([\n            ideal_position + position_noise,\n            ideal_velocity + velocity_noise,\n            ideal_orientation + orientation_noise\n        ]) + systematic_error\n\n        return state\n\n    def analyze_reality_gap(self):\n        """Analyze the reality gap between simulation and real data."""\n        print("Analyzing reality gap...")\n\n        if len(self.simulation_data) == 0 or len(self.real_data) == 0:\n            print("Need both simulation and real data to analyze reality gap")\n            return\n\n        # Align data by control input (assuming same control inputs were used)\n        min_samples = min(len(self.simulation_data), len(self.real_data))\n\n        sim_states = np.array([d[\'state\'] for d in self.simulation_data[:min_samples]])\n        real_states = np.array([d[\'state\'] for d in self.real_data[:min_samples]])\n\n        # Calculate various gap metrics\n        mse = mean_squared_error(sim_states, real_states)\n        rmse = np.sqrt(mse)\n        mae = np.mean(np.abs(sim_states - real_states))\n        r2 = r2_score(sim_states, real_states)\n\n        # Calculate state-wise differences\n        state_differences = np.abs(sim_states - real_states)\n        avg_state_diff = np.mean(state_differences, axis=0)\n        std_state_diff = np.std(state_differences, axis=0)\n\n        # Calculate correlation between sim and real states\n        correlations = []\n        for i in range(sim_states.shape[1]):\n            corr = np.corrcoef(sim_states[:, i], real_states[:, i])[0, 1]\n            correlations.append(corr if not np.isnan(corr) else 0)\n\n        self.gap_metrics = {\n            \'mse\': mse,\n            \'rmse\': rmse,\n            \'mae\': mae,\n            \'r2_score\': r2,\n            \'avg_state_difference\': avg_state_diff,\n            \'std_state_difference\': std_state_diff,\n            \'correlations\': correlations,\n            \'sample_size\': min_samples\n        }\n\n        print(f"Reality Gap Analysis Results:")\n        print(f"  MSE: {mse:.6f}")\n        print(f"  RMSE: {rmse:.6f}")\n        print(f"  MAE: {mae:.6f}")\n        print(f"  R\xb2 Score: {r2:.6f}")\n        print(f"  Average State Difference: {avg_state_diff}")\n        print(f"  State Correlations: {correlations}")\n\n        return self.gap_metrics\n\n    def visualize_reality_gap(self):\n        """Visualize the reality gap analysis."""\n        if not self.gap_metrics:\n            print("Run analyze_reality_gap() first")\n            return\n\n        # Prepare data for visualization\n        min_samples = self.gap_metrics[\'sample_size\']\n        sim_states = np.array([d[\'state\'] for d in self.simulation_data[:min_samples]])\n        real_states = np.array([d[\'state\'] for d in self.real_data[:min_samples]])\n\n        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n        axes = axes.flatten()\n\n        state_names = [\'Pos X\', \'Pos Y\', \'Pos Z\', \'Vel X\', \'Vel Y\', \'Vel Z\']\n\n        for i in range(6):\n            axes[i].scatter(sim_states[:, i], real_states[:, i], alpha=0.6, s=1)\n            axes[i].plot([sim_states[:, i].min(), sim_states[:, i].max()],\n                        [sim_states[:, i].min(), sim_states[:, i].max()], \'r--\', lw=2)\n            axes[i].set_xlabel(f\'Simulated {state_names[i]}\')\n            axes[i].set_ylabel(f\'Real {state_names[i]}\')\n            axes[i].set_title(f\'{state_names[i]}: R\xb2 = {self.gap_metrics["correlations"][i]:.3f}\')\n\n        plt.tight_layout()\n        plt.savefig(\'reality_gap_analysis.png\', dpi=300, bbox_inches=\'tight\')\n        plt.show()\n\n        # Plot state differences over time\n        fig, ax = plt.subplots(figsize=(12, 6))\n        time_steps = range(min_samples)\n        state_diff = np.abs(sim_states - real_states)\n\n        for i in range(6):\n            ax.plot(time_steps, state_diff[:, i], label=state_names[i], alpha=0.7)\n\n        ax.set_xlabel(\'Time Step\')\n        ax.set_ylabel(\'Absolute Difference\')\n        ax.set_title(\'State Differences Over Time\')\n        ax.legend()\n        ax.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        plt.savefig(\'state_differences_over_time.png\', dpi=300, bbox_inches=\'tight\')\n        plt.show()\n\n    def calculate_transfer_efficiency(self):\n        """Calculate transfer efficiency metrics."""\n        if not self.gap_metrics:\n            print("Run analyze_reality_gap() first")\n            return\n\n        # Transfer efficiency based on correlation\n        avg_correlation = np.mean(self.gap_metrics[\'correlations\'])\n\n        # Transfer efficiency based on prediction accuracy\n        efficiency_score = max(0, min(1, avg_correlation))  # Clamp between 0 and 1\n\n        # Additional metrics\n        prediction_accuracy = 1.0 / (1.0 + self.gap_metrics[\'rmse\'])  # Higher RMSE = lower accuracy\n\n        transfer_metrics = {\n            \'correlation_based_efficiency\': avg_correlation,\n            \'prediction_accuracy\': prediction_accuracy,\n            \'overall_efficiency\': (avg_correlation + prediction_accuracy) / 2\n        }\n\n        print(f"Transfer Efficiency Metrics:")\n        for metric, value in transfer_metrics.items():\n            print(f"  {metric}: {value:.4f}")\n\n        return transfer_metrics\n\n# Example usage\nif __name__ == "__main__":\n    analyzer = RealityGapAnalyzer()\n    analyzer.collect_simulation_data(num_samples=1000)\n    analyzer.collect_real_data(num_samples=800)\n    gap_metrics = analyzer.analyze_reality_gap()\n    transfer_metrics = analyzer.calculate_transfer_efficiency()\n    analyzer.visualize_reality_gap()\n\n    print("\\nReality gap analysis completed successfully")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"exercise-2-domain-randomization-implementation",children:"Exercise 2: Domain Randomization Implementation"}),"\n",(0,a.jsx)(n.h3,{id:"step-1-create-domain-randomization-system",children:"Step 1: Create domain randomization system"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/isaac_sim_examples/domain_randomization_system.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n# domain_randomization_system.py\n"""Domain randomization system for sim-to-real transfer."""\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import defaultdict\nimport random\n\nclass DomainRandomizationSystem:\n    """System for implementing domain randomization."""\n\n    def __init__(self):\n        self.randomization_ranges = {\n            \'physics\': {\n                \'mass_ratio\': [0.8, 1.2],\n                \'friction\': [0.5, 1.5],\n                \'restitution\': [0.0, 0.2],\n                \'damping_ratio\': [0.8, 1.2],\n                \'actuator_strength\': [0.8, 1.2],\n                \'gravity\': [0.8, 1.2]  # Scaling factor for gravity\n            },\n            \'visual\': {\n                \'lighting_intensity\': [0.5, 2.0],\n                \'lighting_color_temp\': [0.8, 1.2],\n                \'material_albedo\': [0.5, 1.0],\n                \'material_roughness\': [0.0, 1.0],\n                \'material_metallic\': [0.0, 1.0]\n            },\n            \'sensor\': {\n                \'noise_std\': [0.0, 0.05],\n                \'bias\': [-0.02, 0.02],\n                \'delay_ms\': [0, 20],\n                \'dropout_rate\': [0.0, 0.1]\n            }\n        }\n\n        self.current_parameters = {}\n        self.parameter_history = defaultdict(list)\n        self.episode_count = 0\n\n    def randomize_physics_parameters(self):\n        """Randomize physics parameters."""\n        for param, range_vals in self.randomization_ranges[\'physics\'].items():\n            value = np.random.uniform(range_vals[0], range_vals[1])\n            self.current_parameters[param] = value\n            self.parameter_history[param].append(value)\n\n        print(f"Physics parameters randomized: {self.current_parameters}")\n\n    def randomize_visual_parameters(self):\n        """Randomize visual parameters."""\n        for param, range_vals in self.randomization_ranges[\'visual\'].items():\n            value = np.random.uniform(range_vals[0], range_vals[1])\n            self.current_parameters[param] = value\n            self.parameter_history[param].append(value)\n\n        print(f"Visual parameters randomized: {self.current_parameters}")\n\n    def randomize_sensor_parameters(self):\n        """Randomize sensor parameters."""\n        for param, range_vals in self.randomization_ranges[\'sensor\'].items():\n            value = np.random.uniform(range_vals[0], range_vals[1])\n            self.current_parameters[param] = value\n            self.parameter_history[param].append(value)\n\n        print(f"Sensor parameters randomized: {self.current_parameters}")\n\n    def update_randomization(self, episode_interval=10):\n        """Update randomization parameters based on episode count."""\n        if self.episode_count % episode_interval == 0:\n            self.randomize_physics_parameters()\n            self.randomize_visual_parameters()\n            self.randomize_sensor_parameters()\n\n        self.episode_count += 1\n\n    def get_randomized_parameters(self):\n        """Get current randomized parameters."""\n        return self.current_parameters.copy()\n\n    def apply_to_simulation(self, sim_env):\n        """Apply current randomization parameters to simulation environment."""\n        # This would typically involve updating the physics engine parameters\n        # For demonstration, we\'ll just print what would be applied\n\n        print("Applying randomization to simulation:")\n        for param, value in self.current_parameters.items():\n            print(f"  {param}: {value}")\n\n        # In a real implementation, you would:\n        # - Update physics properties in the simulator\n        # - Change material properties\n        # - Adjust lighting conditions\n        # - Add sensor noise/models\n\n    def calculate_diversity_score(self):\n        """Calculate diversity score of randomization."""\n        if not self.parameter_history:\n            return 0.0\n\n        diversity_scores = []\n        for param, values in self.parameter_history.items():\n            if len(values) > 1:\n                # Calculate standard deviation as a measure of diversity\n                std_dev = np.std(values)\n                diversity_scores.append(std_dev)\n\n        return np.mean(diversity_scores) if diversity_scores else 0.0\n\n    def get_randomization_statistics(self):\n        """Get statistics about randomization."""\n        stats = {}\n        for param, values in self.parameter_history.items():\n            if values:\n                stats[param] = {\n                    \'min\': np.min(values),\n                    \'max\': np.max(values),\n                    \'mean\': np.mean(values),\n                    \'std\': np.std(values),\n                    \'count\': len(values)\n                }\n\n        return stats\n\nclass AdaptiveDomainRandomization(DomainRandomizationSystem):\n    """Adaptive domain randomization that adjusts based on training progress."""\n\n    def __init__(self):\n        super().__init__()\n        self.performance_history = []\n        self.diversity_threshold = 0.1\n        self.adaptation_enabled = True\n\n    def update_with_performance(self, episode_reward, episode_success):\n        """Update randomization based on performance."""\n        self.performance_history.append({\n            \'reward\': episode_reward,\n            \'success\': episode_success,\n            \'episode\': self.episode_count\n        })\n\n        # If performance is plateauing, increase diversity\n        if len(self.performance_history) >= 10:\n            recent_performance = self.performance_history[-10:]\n            avg_recent = np.mean([p[\'reward\'] for p in recent_performance])\n\n            # Calculate trend\n            if len(self.performance_history) >= 20:\n                older_performance = self.performance_history[-20:-10]\n                avg_older = np.mean([p[\'reward\'] for p in older_performance])\n\n                # If no improvement, increase randomization diversity\n                if avg_recent <= avg_older:\n                    self.increase_diversity()\n\n        self.episode_count += 1\n\n    def increase_diversity(self):\n        """Increase diversity of randomization ranges."""\n        print("Increasing randomization diversity due to plateauing performance")\n\n        # Expand randomization ranges\n        for category in self.randomization_ranges.values():\n            for param, range_vals in category.items():\n                center = (range_vals[0] + range_vals[1]) / 2\n                width = range_vals[1] - range_vals[0]\n\n                # Increase range by 10%\n                new_width = width * 1.1\n                new_range = [center - new_width/2, center + new_width/2]\n\n                # Ensure reasonable bounds\n                new_range[0] = max(0, new_range[0])  # Lower bound\n                new_range[1] = min(2.0, new_range[1])  # Upper bound\n\n                category[param] = new_range\n\n    def decrease_diversity(self):\n        """Decrease diversity of randomization ranges."""\n        print("Decreasing randomization diversity due to good performance")\n\n        # Shrink randomization ranges\n        for category in self.randomization_ranges.values():\n            for param, range_vals in category.items():\n                center = (range_vals[0] + range_vals[1]) / 2\n                width = range_vals[1] - range_vals[0]\n\n                # Decrease range by 5%\n                new_width = max(0.1, width * 0.95)  # Minimum width of 0.1\n                new_range = [center - new_width/2, center + new_width/2]\n\n                category[param] = new_range\n\n# Example usage\nif __name__ == "__main__":\n    # Basic domain randomization\n    dr_system = DomainRandomizationSystem()\n\n    print("Basic Domain Randomization System:")\n    for i in range(5):\n        dr_system.update_randomization(episode_interval=1)  # Update every episode\n        params = dr_system.get_randomized_parameters()\n        print(f"Episode {i+1} parameters: {params}")\n\n    diversity = dr_system.calculate_diversity_score()\n    print(f"Diversity score: {diversity:.4f}")\n\n    stats = dr_system.get_randomization_statistics()\n    print(f"Statistics calculated for {len(stats)} parameters")\n\n    # Adaptive domain randomization\n    adaptive_dr = AdaptiveDomainRandomization()\n\n    print("\\nAdaptive Domain Randomization:")\n    for i in range(10):\n        # Simulate some performance metrics\n        reward = np.random.uniform(0, 100)\n        success = random.random() > 0.5\n\n        adaptive_dr.update_with_performance(reward, success)\n        params = adaptive_dr.get_randomized_parameters()\n        print(f"Episode {i+1}: Reward={reward:.2f}, Success={success}")\n\n    print(f"Final diversity score: {adaptive_dr.calculate_diversity_score():.4f}")\n\n    print("\\nDomain randomization system completed successfully")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"exercise-3-system-identification",children:"Exercise 3: System Identification"}),"\n",(0,a.jsx)(n.h3,{id:"step-1-create-system-identification-tools",children:"Step 1: Create system identification tools"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/isaac_sim_examples/system_identification.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n# system_identification.py\n"""System identification for robot modeling and sim-to-real transfer."""\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.signal import butter, filtfilt\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass SystemIdentifier:\n    """System identification for robot dynamics modeling."""\n\n    def __init__(self, robot_type=\'wheeled\'):\n        self.robot_type = robot_type\n        self.model = None\n        self.input_data = []\n        self.output_data = []\n        self.identification_method = \'linear\'\n        self.model_order = 2\n\n    def collect_data(self, inputs, outputs, timestamps=None):\n        """Collect input-output data for system identification."""\n        if timestamps is None:\n            timestamps = np.arange(len(inputs))\n\n        self.input_data.extend(inputs)\n        self.output_data.extend(outputs)\n\n        print(f"Collected {len(inputs)} data points. Total: {len(self.input_data)}")\n\n    def identify_model(self, method=\'linear\', model_order=2):\n        """Identify system model using collected data."""\n        if len(self.input_data) < 10:\n            print("Need at least 10 data points for system identification")\n            return False\n\n        self.identification_method = method\n        self.model_order = model_order\n\n        X = np.array(self.input_data)\n        Y = np.array(self.output_data)\n\n        if method == \'linear\':\n            self.model = self.identify_linear_model(X, Y)\n        elif method == \'polynomial\':\n            self.model = self.identify_polynomial_model(X, Y, model_order)\n        elif method == \'neural\':\n            self.model = self.identify_neural_model(X, Y)\n        else:\n            print(f"Unknown identification method: {method}")\n            return False\n\n        print(f"System model identified using {method} method")\n        return True\n\n    def identify_linear_model(self, X, Y):\n        """Identify linear system model."""\n        # Use ridge regression for regularization\n        model = Ridge(alpha=1.0)\n        model.fit(X, Y)\n        return model\n\n    def identify_polynomial_model(self, X, Y, order=2):\n        """Identify polynomial system model."""\n        # Create polynomial features\n        poly_features = PolynomialFeatures(degree=order)\n        X_poly = poly_features.fit_transform(X)\n\n        # Fit linear model on polynomial features\n        model = Ridge(alpha=1.0)\n        model.fit(X_poly, Y)\n\n        # Store polynomial features for later use\n        model.poly_features = poly_features\n        return model\n\n    def identify_neural_model(self, X, Y, hidden_size=64, epochs=1000):\n        """Identify neural network model."""\n        class NeuralDynamicsModel(nn.Module):\n            def __init__(self, input_size, output_size, hidden_size):\n                super(NeuralDynamicsModel, self).__init__()\n                self.network = nn.Sequential(\n                    nn.Linear(input_size, hidden_size),\n                    nn.ReLU(),\n                    nn.Linear(hidden_size, hidden_size),\n                    nn.ReLU(),\n                    nn.Linear(hidden_size, output_size)\n                )\n\n            def forward(self, x):\n                return self.network(x)\n\n        # Convert to tensors\n        X_tensor = torch.FloatTensor(X)\n        Y_tensor = torch.FloatTensor(Y)\n\n        # Create model\n        model = NeuralDynamicsModel(X.shape[1], Y.shape[1], hidden_size)\n\n        # Train model\n        criterion = nn.MSELoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        for epoch in range(epochs):\n            optimizer.zero_grad()\n            outputs = model(X_tensor)\n            loss = criterion(outputs, Y_tensor)\n            loss.backward()\n            optimizer.step()\n\n            if epoch % 200 == 0:\n                print(f\'Neural model training: Epoch {epoch}, Loss: {loss.item():.6f}\')\n\n        return model\n\n    def predict(self, inputs):\n        """Predict system output using identified model."""\n        if self.model is None:\n            print("Model not identified yet")\n            return None\n\n        inputs = np.array(inputs)\n\n        if self.identification_method == \'neural\':\n            with torch.no_grad():\n                input_tensor = torch.FloatTensor(inputs)\n                if len(input_tensor.shape) == 1:\n                    input_tensor = input_tensor.unsqueeze(0)\n                output_tensor = self.model(input_tensor)\n                return output_tensor.numpy()\n        else:\n            if self.identification_method == \'polynomial\':\n                inputs = self.model.poly_features.transform(inputs.reshape(1, -1))\n            return self.model.predict(inputs)\n\n    def evaluate_model(self, test_inputs, test_outputs):\n        """Evaluate identified model performance."""\n        if self.model is None:\n            print("Model not identified yet")\n            return None\n\n        predictions = self.predict(test_inputs)\n        if predictions is None:\n            return None\n\n        mse = np.mean((predictions - test_outputs) ** 2)\n        rmse = np.sqrt(mse)\n        mae = np.mean(np.abs(predictions - test_outputs))\n\n        # Calculate R\xb2 score\n        ss_res = np.sum((test_outputs - predictions) ** 2)\n        ss_tot = np.sum((test_outputs - np.mean(test_outputs)) ** 2)\n        r2 = 1 - (ss_res / ss_tot)\n\n        metrics = {\n            \'mse\': mse,\n            \'rmse\': rmse,\n            \'mae\': mae,\n            \'r2_score\': r2\n        }\n\n        print(f"Model Evaluation Metrics:")\n        for metric, value in metrics.items():\n            print(f"  {metric}: {value:.6f}")\n\n        return metrics\n\n    def visualize_identification(self):\n        """Visualize system identification results."""\n        if self.model is None or len(self.input_data) == 0:\n            print("No model or data available for visualization")\n            return\n\n        X = np.array(self.input_data)\n        Y = np.array(self.output_data)\n\n        predictions = self.predict(X)\n\n        if predictions is None:\n            return\n\n        # Plot results\n        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n        # Plot 1: Actual vs Predicted\n        axes[0, 0].scatter(Y.flatten(), predictions.flatten(), alpha=0.6)\n        min_val = min(Y.min(), predictions.min())\n        max_val = max(Y.max(), predictions.max())\n        axes[0, 0].plot([min_val, max_val], [min_val, max_val], \'r--\', lw=2)\n        axes[0, 0].set_xlabel(\'Actual\')\n        axes[0, 0].set_ylabel(\'Predicted\')\n        axes[0, 0].set_title(\'Actual vs Predicted\')\n\n        # Plot 2: Prediction errors\n        errors = Y.flatten() - predictions.flatten()\n        axes[0, 1].hist(errors, bins=50, alpha=0.7)\n        axes[0, 1].set_xlabel(\'Prediction Error\')\n        axes[0, 1].set_ylabel(\'Frequency\')\n        axes[0, 1].set_title(\'Distribution of Prediction Errors\')\n\n        # Plot 3: Time series comparison\n        time_steps = range(len(Y))\n        axes[1, 0].plot(time_steps, Y.flatten(), label=\'Actual\', alpha=0.7)\n        axes[1, 0].plot(time_steps, predictions.flatten(), label=\'Predicted\', alpha=0.7)\n        axes[1, 0].set_xlabel(\'Time Step\')\n        axes[1, 0].set_ylabel(\'Value\')\n        axes[1, 0].set_title(\'Time Series Comparison\')\n        axes[1, 0].legend()\n\n        # Plot 4: Error over time\n        axes[1, 1].plot(time_steps, errors, alpha=0.7)\n        axes[1, 1].set_xlabel(\'Time Step\')\n        axes[1, 1].set_ylabel(\'Error\')\n        axes[1, 1].set_title(\'Prediction Error Over Time\')\n\n        plt.tight_layout()\n        plt.savefig(\'system_identification_results.png\', dpi=300, bbox_inches=\'tight\')\n        plt.show()\n\nclass PhysicsParameterEstimator:\n    """Estimate physics parameters from system identification results."""\n\n    def __init__(self):\n        self.estimated_parameters = {}\n        self.uncertainty_bounds = {}\n\n    def estimate_mass_properties(self, acceleration_data, force_data):\n        """Estimate mass properties using F = ma."""\n        # F = ma => m = F/a\n        # Use least squares to estimate mass from multiple measurements\n        valid_indices = acceleration_data != 0  # Avoid division by zero\n\n        if np.sum(valid_indices) < 1:\n            return None\n\n        accelerations = acceleration_data[valid_indices]\n        forces = force_data[valid_indices]\n\n        # Estimate mass using least squares\n        masses = forces / accelerations\n        estimated_mass = np.mean(masses)\n        uncertainty = np.std(masses)\n\n        self.estimated_parameters[\'mass\'] = estimated_mass\n        self.uncertainty_bounds[\'mass\'] = uncertainty\n\n        print(f"Estimated mass: {estimated_mass:.4f} \xb1 {uncertainty:.4f} kg")\n\n    def estimate_friction_coefficients(self, velocity_data, force_data):\n        """Estimate friction coefficients."""\n        # Model: F_friction = mu * N (normal force)\n        # For horizontal motion: F_applied - F_friction = ma\n        # So F_friction = F_applied - ma\n\n        # This is a simplified model - in reality, you\'d need more complex analysis\n        friction_estimates = force_data  # Simplified for this example\n\n        avg_friction = np.mean(friction_estimates)\n        friction_uncertainty = np.std(friction_estimates)\n\n        self.estimated_parameters[\'friction\'] = avg_friction\n        self.uncertainty_bounds[\'friction\'] = friction_uncertainty\n\n        print(f"Estimated friction: {avg_friction:.4f} \xb1 {friction_uncertainty:.4f} N")\n\n    def estimate_damping_coefficients(self, velocity_data, force_data):\n        """Estimate damping coefficients."""\n        # Model: F_damping = b * v (linear damping)\n        # Use least squares to estimate damping coefficient b\n\n        # Only use data where velocity is not zero\n        valid_indices = velocity_data != 0\n\n        if np.sum(valid_indices) < 2:\n            return None\n\n        velocities = velocity_data[valid_indices]\n        forces = force_data[valid_indices]\n\n        # Estimate damping coefficient using least squares\n        # F = b*v => b = F/v (when v != 0)\n        damping_coeffs = forces / velocities\n        estimated_damping = np.mean(damping_coeffs)\n        uncertainty = np.std(damping_coeffs)\n\n        self.estimated_parameters[\'damping\'] = estimated_damping\n        self.uncertainty_bounds[\'damping\'] = uncertainty\n\n        print(f"Estimated damping: {estimated_damping:.4f} \xb1 {uncertainty:.4f} Ns/m")\n\n    def get_estimated_parameters(self):\n        """Get estimated physics parameters."""\n        return self.estimated_parameters.copy()\n\n    def get_uncertainty_bounds(self):\n        """Get uncertainty bounds for estimated parameters."""\n        return self.uncertainty_bounds.copy()\n\n# Example usage\nif __name__ == "__main__":\n    print("System Identification Example")\n\n    # Create system identifier\n    sys_id = SystemIdentifier(robot_type=\'wheeled\')\n\n    # Generate synthetic data for demonstration\n    np.random.seed(42)\n    n_samples = 1000\n\n    # Inputs: control commands (forces, torques)\n    inputs = np.random.uniform(-10, 10, size=(n_samples, 3))  # 3 DoF control\n\n    # Outputs: resulting states (position, velocity changes)\n    # Simulate some dynamics: y = 0.5*x + noise\n    outputs = 0.5 * inputs + 0.1 * np.random.randn(n_samples, 3)\n\n    # Add some non-linearities\n    outputs += 0.05 * inputs**2\n\n    # Collect data\n    sys_id.collect_data(inputs, outputs)\n\n    # Identify models using different methods\n    methods = [\'linear\', \'polynomial\', \'neural\']\n\n    for method in methods:\n        print(f"\\nIdentifying model using {method} method...")\n        success = sys_id.identify_model(method=method, model_order=2)\n\n        if success:\n            # Evaluate model\n            test_inputs = inputs[-100:]  # Use last 100 samples as test\n            test_outputs = outputs[-100:]\n            metrics = sys_id.evaluate_model(test_inputs, test_outputs)\n\n            if metrics:\n                print(f"{method.upper()} model - R\xb2 Score: {metrics[\'r2_score\']:.4f}")\n\n    # Visualize results for the best model (in practice, you\'d select based on metrics)\n    sys_id.visualize_identification()\n\n    # Physics parameter estimation\n    print("\\nPhysics Parameter Estimation:")\n    physics_estimator = PhysicsParameterEstimator()\n\n    # Example: estimate parameters from collected data\n    velocity_data = outputs[:, 0]  # Use first output as velocity\n    force_data = inputs[:, 0]      # Use first input as force\n\n    physics_estimator.estimate_mass_properties(velocity_data, force_data)\n    physics_estimator.estimate_friction_coefficients(velocity_data, force_data)\n    physics_estimator.estimate_damping_coefficients(velocity_data, force_data)\n\n    estimated_params = physics_estimator.get_estimated_parameters()\n    print(f"Final estimated parameters: {estimated_params}")\n\n    print("\\nSystem identification completed successfully")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"exercise-4-model-adaptation-and-fine-tuning",children:"Exercise 4: Model Adaptation and Fine-Tuning"}),"\n",(0,a.jsx)(n.h3,{id:"step-1-create-model-adaptation-system",children:"Step 1: Create model adaptation system"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/isaac_sim_examples/model_adaptation.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n# model_adaptation.py\n"""Model adaptation and fine-tuning for sim-to-real transfer."""\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport copy\n\nclass ModelAdapter:\n    """Adapt simulation models for real-world deployment."""\n\n    def __init__(self, simulation_model):\n        self.simulation_model = simulation_model\n        self.adapted_model = None\n        self.scaler = StandardScaler()\n        self.adaptation_history = []\n\n    def adapt_with_real_data(self, real_inputs, real_outputs, adaptation_method=\'fine_tune\'):\n        """Adapt model using real-world data."""\n        print(f"Adapting model using {adaptation_method} method...")\n\n        # Standardize the data\n        real_inputs_scaled = self.scaler.fit_transform(real_inputs)\n        real_outputs_scaled = self.scaler.fit_transform(real_outputs)\n\n        if adaptation_method == \'fine_tune\':\n            self.adapted_model = self.fine_tune_model(real_inputs_scaled, real_outputs_scaled)\n        elif adaptation_method == \'domain_adaptation\':\n            self.adapted_model = self.domain_adaptation(real_inputs_scaled, real_outputs_scaled)\n        elif adaptation_method == \'ensemble\':\n            self.adapted_model = self.ensemble_adaptation(real_inputs_scaled, real_outputs_scaled)\n        else:\n            print(f"Unknown adaptation method: {adaptation_method}")\n            return False\n\n        print(f"Model adaptation completed using {adaptation_method} method")\n        return True\n\n    def fine_tune_model(self, real_inputs, real_outputs, learning_rate=1e-4, epochs=100):\n        """Fine-tune simulation model with real data."""\n        # Clone the simulation model\n        adapted_model = copy.deepcopy(self.simulation_model)\n        adapted_model.train()\n\n        # Convert to tensors\n        inputs_tensor = torch.FloatTensor(real_inputs)\n        outputs_tensor = torch.FloatTensor(real_outputs)\n\n        # Create dataset and dataloader\n        dataset = TensorDataset(inputs_tensor, outputs_tensor)\n        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n        # Use the same optimizer as the original model (if available)\n        # For this example, we\'ll create a new optimizer\n        optimizer = optim.Adam(adapted_model.parameters(), lr=learning_rate)\n        criterion = nn.MSELoss()\n\n        # Fine-tuning loop\n        for epoch in range(epochs):\n            total_loss = 0\n            for batch_inputs, batch_outputs in dataloader:\n                optimizer.zero_grad()\n                predictions = adapted_model(batch_inputs)\n                loss = criterion(predictions, batch_outputs)\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n\n            if epoch % 20 == 0:\n                avg_loss = total_loss / len(dataloader)\n                print(f\'Fine-tuning Epoch {epoch}, Average Loss: {avg_loss:.6f}\')\n\n        return adapted_model\n\n    def domain_adaptation(self, real_inputs, real_outputs):\n        """Implement domain adaptation using adversarial training."""\n        # Create domain adaptation model\n        class DomainAdaptationModel(nn.Module):\n            def __init__(self, base_model):\n                super(DomainAdaptationModel, self).__init__()\n                self.base_model = base_model\n                # Add domain classifier\n                self.domain_classifier = nn.Sequential(\n                    nn.Linear(base_model.network[-1].out_features, 64),\n                    nn.ReLU(),\n                    nn.Linear(64, 32),\n                    nn.ReLU(),\n                    nn.Linear(32, 2)  # Binary classification: sim vs real\n                )\n\n            def forward(self, x, domain_label=None):\n                features = self.base_model(x)\n                if domain_label is not None:\n                    domain_pred = self.domain_classifier(features)\n                    return features, domain_pred\n                return features\n\n        # This is a simplified implementation\n        # In practice, you\'d implement adversarial training\n        adapted_model = self.fine_tune_model(real_inputs, real_outputs)\n        return adapted_model\n\n    def ensemble_adaptation(self, real_inputs, real_outputs):\n        """Create ensemble of adapted models."""\n        models = []\n\n        # Create multiple models with different adaptations\n        for i in range(3):  # Create 3 models\n            # Add noise to real data to create variations\n            noisy_inputs = real_inputs + np.random.normal(0, 0.01, real_inputs.shape)\n            noisy_outputs = real_outputs + np.random.normal(0, 0.01, real_outputs.shape)\n\n            model = self.fine_tune_model(noisy_inputs, noisy_outputs, epochs=50)\n            models.append(model)\n\n        # Create ensemble wrapper\n        class EnsembleModel(nn.Module):\n            def __init__(self, models):\n                super(EnsembleModel, self).__init__()\n                self.models = nn.ModuleList(models)\n\n            def forward(self, x):\n                outputs = []\n                for model in self.models:\n                    outputs.append(model(x))\n                # Average predictions\n                return torch.stack(outputs).mean(dim=0)\n\n        ensemble_model = EnsembleModel(models)\n        return ensemble_model\n\n    def predict(self, inputs):\n        """Make predictions using adapted model."""\n        if self.adapted_model is None:\n            print("Model not adapted yet")\n            return None\n\n        inputs_scaled = self.scaler.transform(inputs.reshape(1, -1))\n        inputs_tensor = torch.FloatTensor(inputs_scaled)\n\n        with torch.no_grad():\n            prediction = self.adapted_model(inputs_tensor)\n\n        # Inverse transform the prediction\n        prediction_unscaled = self.scaler.inverse_transform(prediction.numpy())\n        return prediction_unscaled\n\n    def evaluate_adaptation(self, test_inputs, test_outputs):\n        """Evaluate the adapted model."""\n        if self.adapted_model is None:\n            print("Model not adapted yet")\n            return None\n\n        predictions = []\n        for input_vec in test_inputs:\n            pred = self.predict(input_vec)\n            if pred is not None:\n                predictions.append(pred.flatten())\n\n        if not predictions:\n            return None\n\n        predictions = np.array(predictions)\n\n        # Calculate metrics\n        mse = np.mean((predictions - test_outputs) ** 2)\n        rmse = np.sqrt(mse)\n        mae = np.mean(np.abs(predictions - test_outputs))\n\n        # R\xb2 score\n        ss_res = np.sum((test_outputs - predictions) ** 2)\n        ss_tot = np.sum((test_outputs - np.mean(test_outputs)) ** 2)\n        r2 = 1 - (ss_res / ss_tot)\n\n        metrics = {\n            \'mse\': mse,\n            \'rmse\': rmse,\n            \'mae\': mae,\n            \'r2_score\': r2\n        }\n\n        print("Adapted Model Evaluation:")\n        for metric, value in metrics.items():\n            print(f"  {metric}: {value:.6f}")\n\n        return metrics\n\nclass OnlineAdaptationSystem:\n    """Online adaptation system for continuous learning."""\n\n    def __init__(self, base_model, adaptation_rate=0.01):\n        self.base_model = base_model\n        self.current_model = copy.deepcopy(base_model)\n        self.adaptation_rate = adaptation_rate\n        self.performance_threshold = 0.05  # Threshold for triggering adaptation\n        self.performance_history = []\n\n    def update_model_online(self, input_data, target_data, current_performance):\n        """Update model online based on performance."""\n        self.performance_history.append(current_performance)\n\n        # Check if adaptation is needed\n        if len(self.performance_history) >= 10:\n            recent_avg = np.mean(self.performance_history[-10:])\n            overall_avg = np.mean(self.performance_history)\n\n            # If performance degrades significantly, adapt\n            if recent_avg < overall_avg - self.performance_threshold:\n                print("Performance degradation detected, adapting model...")\n                self.adapt_online(input_data, target_data)\n\n    def adapt_online(self, input_data, target_data):\n        """Perform online adaptation."""\n        # Convert to tensors\n        input_tensor = torch.FloatTensor(input_data).unsqueeze(0)\n        target_tensor = torch.FloatTensor(target_data).unsqueeze(0)\n\n        # Simple gradient step adaptation\n        self.current_model.train()\n        optimizer = optim.SGD(self.current_model.parameters(), lr=self.adaptation_rate)\n\n        optimizer.zero_grad()\n        prediction = self.current_model(input_tensor)\n        loss = nn.MSELoss()(prediction, target_tensor)\n        loss.backward()\n        optimizer.step()\n\n        print(f"Online adaptation completed. Loss: {loss.item():.6f}")\n\n    def predict(self, input_data):\n        """Make prediction with current model."""\n        input_tensor = torch.FloatTensor(input_data).unsqueeze(0)\n\n        with torch.no_grad():\n            self.current_model.eval()\n            prediction = self.current_model(input_tensor)\n            return prediction.numpy().flatten()\n\n# Example usage\nif __name__ == "__main__":\n    print("Model Adaptation System Example")\n\n    # Create a simple simulation model (for demonstration)\n    class SimpleSimulationModel(nn.Module):\n        def __init__(self, input_size=3, output_size=3):\n            super(SimpleSimulationModel, self).__init__()\n            self.network = nn.Sequential(\n                nn.Linear(input_size, 64),\n                nn.ReLU(),\n                nn.Linear(64, 32),\n                nn.ReLU(),\n                nn.Linear(32, output_size)\n            )\n\n        def forward(self, x):\n            return self.network(x)\n\n    # Create simulation model\n    sim_model = SimpleSimulationModel()\n\n    # Generate synthetic data\n    np.random.seed(42)\n    n_samples = 500\n\n    # Real data (slightly different from simulation)\n    real_inputs = np.random.uniform(-1, 1, size=(n_samples, 3))\n    real_outputs = 0.8 * real_inputs + 0.05 * np.random.randn(n_samples, 3)  # Different scaling\n\n    # Test data\n    test_inputs = np.random.uniform(-1, 1, size=(100, 3))\n    test_outputs = 0.8 * test_inputs + 0.05 * np.random.randn(100, 3)\n\n    print("Original simulation model performance:")\n    with torch.no_grad():\n        sim_predictions = sim_model(torch.FloatTensor(test_inputs))\n        sim_mse = nn.MSELoss()(sim_predictions, torch.FloatTensor(test_outputs)).item()\n        print(f"  MSE: {sim_mse:.6f}")\n\n    # Test model adaptation\n    methods = [\'fine_tune\', \'ensemble\']\n\n    for method in methods:\n        print(f"\\nTesting {method} adaptation...")\n        adapter = ModelAdapter(sim_model)\n        success = adapter.adapt_with_real_data(real_inputs, real_outputs, method)\n\n        if success:\n            metrics = adapter.evaluate_adaptation(test_inputs, test_outputs)\n            if metrics:\n                print(f"  Adapted model MSE: {metrics[\'mse\']:.6f}")\n\n    # Test online adaptation\n    print(f"\\nTesting online adaptation...")\n    online_adapter = OnlineAdaptationSystem(sim_model)\n\n    # Simulate online learning scenario\n    for i in range(20):\n        # Generate new data point\n        new_input = np.random.uniform(-1, 1, size=3)\n        new_target = 0.8 * new_input + 0.05 * np.random.randn(3)\n\n        # Get prediction and calculate performance\n        prediction = online_adapter.predict(new_input)\n        performance = -np.mean((prediction - new_target) ** 2)  # Negative MSE as performance\n\n        # Update model if needed\n        online_adapter.update_model_online(new_input, new_target, performance)\n\n        if i % 5 == 0:\n            print(f"  Step {i}: Performance = {performance:.4f}")\n\n    print("\\nModel adaptation system completed successfully")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"exercise-5-validation-and-deployment",children:"Exercise 5: Validation and Deployment"}),"\n",(0,a.jsx)(n.h3,{id:"step-1-create-validation-and-deployment-tools",children:"Step 1: Create validation and deployment tools"}),"\n",(0,a.jsxs)(n.p,{children:["Create ",(0,a.jsx)(n.code,{children:"~/isaac_sim_examples/validation_deployment.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n# validation_deployment.py\n\"\"\"Validation and deployment system for sim-to-real transfer.\"\"\"\n\nimport numpy as np\nimport torch\nimport pickle\nimport json\nimport os\nfrom datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass TransferValidationSystem:\n    \"\"\"System for validating sim-to-real transfer effectiveness.\"\"\"\n\n    def __init__(self):\n        self.simulation_performance = {}\n        self.real_world_performance = {}\n        self.transfer_metrics = {}\n        self.safety_checks = []\n        self.validation_results = {}\n\n    def run_comparative_validation(self, sim_model, real_model, test_scenarios):\n        \"\"\"Run comparative validation between simulation and real models.\"\"\"\n        print(\"Running comparative validation...\")\n\n        sim_results = []\n        real_results = []\n\n        for scenario in test_scenarios:\n            # Test in simulation\n            sim_result = self.test_model_in_environment(sim_model, scenario, 'simulation')\n            sim_results.append(sim_result)\n\n            # Test in real environment (simulated here)\n            real_result = self.test_model_in_environment(real_model, scenario, 'real')\n            real_results.append(real_result)\n\n        # Calculate transfer metrics\n        self.calculate_transfer_metrics(sim_results, real_results)\n\n        return sim_results, real_results\n\n    def test_model_in_environment(self, model, scenario, environment_type):\n        \"\"\"Test model in specific environment.\"\"\"\n        # Simulate testing the model in the given environment\n        # This would involve running the model through various scenarios\n\n        results = {\n            'scenario': scenario['name'],\n            'environment': environment_type,\n            'success_rate': np.random.uniform(0.7, 0.95),  # Simulated results\n            'completion_time': np.random.uniform(10, 30),  # seconds\n            'energy_consumption': np.random.uniform(50, 100),  # arbitrary units\n            'safety_violations': np.random.randint(0, 3),\n            'accuracy': np.random.uniform(0.8, 0.98)\n        }\n\n        return results\n\n    def calculate_transfer_metrics(self, sim_results, real_results):\n        \"\"\"Calculate transfer effectiveness metrics.\"\"\"\n        if len(sim_results) != len(real_results):\n            print(\"Mismatch in simulation and real results length\")\n            return\n\n        metrics = defaultdict(list)\n\n        for sim_res, real_res in zip(sim_results, real_results):\n            # Calculate transfer effectiveness for each metric\n            metrics['success_rate_transfer'].append(\n                (real_res['success_rate'] - sim_res['success_rate']) / sim_res['success_rate']\n            )\n            metrics['time_transfer'].append(\n                (real_res['completion_time'] - sim_res['completion_time']) / sim_res['completion_time']\n            )\n            metrics['accuracy_transfer'].append(\n                (real_res['accuracy'] - sim_res['accuracy']) / sim_res['accuracy']\n            )\n\n        # Calculate average metrics\n        avg_metrics = {}\n        for key, values in metrics.items():\n            avg_metrics[key] = np.mean(values)\n            avg_metrics[f'{key}_std'] = np.std(values)\n\n        self.transfer_metrics = avg_metrics\n        print(\"Transfer metrics calculated:\")\n        for metric, value in avg_metrics.items():\n            print(f\"  {metric}: {value:.4f}\")\n\n    def run_safety_validation(self, model, safety_constraints):\n        \"\"\"Run safety validation tests.\"\"\"\n        print(\"Running safety validation...\")\n\n        safety_results = []\n\n        for constraint in safety_constraints:\n            # Test each safety constraint\n            constraint_result = {\n                'constraint': constraint['name'],\n                'passed': True,\n                'violation_count': 0,\n                'max_violation': 0.0,\n                'details': []\n            }\n\n            # Simulate constraint testing\n            for i in range(100):  # Run 100 test cases\n                # Generate random inputs that might violate constraints\n                test_input = np.random.uniform(-2, 2, size=6)\n\n                # Check if constraint is violated\n                violation = self.check_constraint_violation(test_input, constraint)\n\n                if violation > 0:\n                    constraint_result['violation_count'] += 1\n                    constraint_result['max_violation'] = max(constraint_result['max_violation'], violation)\n                    constraint_result['details'].append({\n                        'input': test_input.tolist(),\n                        'violation': violation\n                    })\n\n                    if constraint['critical']:\n                        constraint_result['passed'] = False\n\n            safety_results.append(constraint_result)\n\n        self.safety_checks = safety_results\n        print(\"Safety validation completed:\")\n        for result in safety_results:\n            status = \"PASS\" if result['passed'] else \"FAIL\"\n            print(f\"  {result['constraint']}: {status} ({result['violation_count']} violations)\")\n\n        return safety_results\n\n    def check_constraint_violation(self, input_data, constraint):\n        \"\"\"Check if input violates safety constraint.\"\"\"\n        # This is a simplified example\n        # In reality, this would check specific safety constraints\n        if constraint['type'] == 'position_limit':\n            # Check if position exceeds limits\n            pos_limits = constraint['limits']\n            for i, (min_val, max_val) in enumerate(pos_limits):\n                if i < len(input_data) and (input_data[i] < min_val or input_data[i] > max_val):\n                    return abs(input_data[i] - (min_val if input_data[i] < min_val else max_val))\n        elif constraint['type'] == 'velocity_limit':\n            # Check if velocity exceeds limits\n            vel_limit = constraint['limit']\n            if abs(input_data[0]) > vel_limit:  # Assume first element is velocity\n                return abs(input_data[0]) - vel_limit\n\n        return 0.0\n\n    def generate_validation_report(self, output_dir='validation_reports'):\n        \"\"\"Generate comprehensive validation report.\"\"\"\n        print(f\"Generating validation report in {output_dir}...\")\n\n        # Create output directory\n        os.makedirs(output_dir, exist_ok=True)\n\n        # Create report data\n        report_data = {\n            'timestamp': datetime.now().isoformat(),\n            'transfer_metrics': self.transfer_metrics,\n            'safety_results': self.safety_checks,\n            'summary': {\n                'transfer_success': self.is_transfer_successful(),\n                'safety_pass': self.are_safety_checks_passed(),\n                'overall_risk': self.calculate_overall_risk()\n            }\n        }\n\n        # Save report as JSON\n        report_path = os.path.join(output_dir, f'validation_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json')\n        with open(report_path, 'w') as f:\n            json.dump(report_data, f, indent=2)\n\n        # Create visualization\n        self.create_validation_visualization(report_data, output_dir)\n\n        print(f\"Validation report saved to: {report_path}\")\n        return report_path\n\n    def is_transfer_successful(self):\n        \"\"\"Check if transfer was successful based on metrics.\"\"\"\n        if not self.transfer_metrics:\n            return False\n\n        # Check if success rate transfer is within acceptable range\n        success_transfer = self.transfer_metrics.get('success_rate_transfer', 0)\n        return success_transfer >= -0.1  # Allow up to 10% drop\n\n    def are_safety_checks_passed(self):\n        \"\"\"Check if all safety checks passed.\"\"\"\n        if not self.safety_checks:\n            return True\n\n        return all(result['passed'] for result in self.safety_checks)\n\n    def calculate_overall_risk(self):\n        \"\"\"Calculate overall risk score.\"\"\"\n        if not self.transfer_metrics:\n            return 1.0  # High risk if no metrics\n\n        # Combine transfer effectiveness and safety\n        transfer_score = 1.0 - abs(self.transfer_metrics.get('success_rate_transfer', 0))\n        safety_score = 1.0 if self.are_safety_checks_passed() else 0.0\n\n        # Weighted average\n        overall_risk = 0.7 * (1.0 - transfer_score) + 0.3 * (1.0 - safety_score)\n        return min(1.0, max(0.0, overall_risk))  # Clamp between 0 and 1\n\n    def create_validation_visualization(self, report_data, output_dir):\n        \"\"\"Create visualization of validation results.\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n        # Plot 1: Transfer metrics\n        transfer_keys = [k for k in report_data['transfer_metrics'].keys() if not k.endswith('_std')]\n        transfer_values = [report_data['transfer_metrics'][k] for k in transfer_keys]\n\n        axes[0, 0].bar(range(len(transfer_keys)), transfer_values)\n        axes[0, 0].set_xticks(range(len(transfer_keys)))\n        axes[0, 0].set_xticklabels([k.replace('_transfer', '') for k in transfer_keys], rotation=45)\n        axes[0, 0].set_title('Transfer Effectiveness Metrics')\n        axes[0, 0].set_ylabel('Change Ratio')\n\n        # Plot 2: Safety results\n        safety_names = [result['constraint'] for result in report_data['safety_results']]\n        safety_passed = [1 if result['passed'] else 0 for result in report_data['safety_results']]\n\n        colors = ['green' if passed else 'red' for passed in safety_passed]\n        axes[0, 1].bar(range(len(safety_names)), safety_passed, color=colors)\n        axes[0, 1].set_xticks(range(len(safety_names)))\n        axes[0, 1].set_xticklabels(safety_names, rotation=45)\n        axes[0, 1].set_title('Safety Check Results')\n        axes[0, 1].set_ylabel('Pass (1) / Fail (0)')\n        axes[0, 1].set_ylim(-0.1, 1.1)\n\n        # Plot 3: Risk assessment\n        risk_categories = ['Transfer Risk', 'Safety Risk', 'Overall Risk']\n        risk_values = [\n            1.0 - report_data['summary'].get('transfer_success', 0.5),\n            1.0 - report_data['summary'].get('safety_pass', 0.5),\n            report_data['summary'].get('overall_risk', 0.5)\n        ]\n\n        bars = axes[1, 0].bar(risk_categories, risk_values)\n        axes[1, 0].set_title('Risk Assessment')\n        axes[1, 0].set_ylabel('Risk Level')\n        axes[1, 0].set_ylim(0, 1)\n\n        # Add value labels on bars\n        for bar, value in zip(bars, risk_values):\n            height = bar.get_height()\n            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n                           f'{value:.2f}',\n                           ha='center', va='bottom')\n\n        # Plot 4: Safety violations\n        violation_counts = [result['violation_count'] for result in report_data['safety_results']]\n        axes[1, 1].bar(range(len(safety_names)), violation_counts)\n        axes[1, 1].set_xticks(range(len(safety_names)))\n        axes[1, 1].set_xticklabels(safety_names, rotation=45)\n        axes[1, 1].set_title('Safety Violation Counts')\n        axes[1, 1].set_ylabel('Violation Count')\n\n        plt.tight_layout()\n        viz_path = os.path.join(output_dir, f'validation_visualization_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png')\n        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n        plt.close()\n\n        print(f\"Validation visualization saved to: {viz_path}\")\n\nclass DeploymentManager:\n    \"\"\"Manage deployment of models to real robots.\"\"\"\n\n    def __init__(self, model_path, robot_interface):\n        self.model_path = model_path\n        self.robot_interface = robot_interface\n        self.deployment_history = []\n        self.active_model = None\n\n    def deploy_model(self, model, validation_report):\n        \"\"\"Deploy model to robot with validation check.\"\"\"\n        print(\"Deploying model to robot...\")\n\n        # Check if validation passed\n        if not self.is_deployment_approved(validation_report):\n            print(\"Deployment rejected: Validation requirements not met\")\n            return False\n\n        # Serialize model\n        model_bytes = self.serialize_model(model)\n\n        # Deploy to robot\n        deployment_success = self.robot_interface.deploy_model(model_bytes)\n\n        if deployment_success:\n            deployment_record = {\n                'timestamp': datetime.now().isoformat(),\n                'model_path': self.model_path,\n                'validation_report': validation_report['timestamp'],\n                'deployment_success': True,\n                'risk_level': validation_report['summary']['overall_risk']\n            }\n            self.deployment_history.append(deployment_record)\n            self.active_model = model\n\n            print(\"Model deployed successfully\")\n            return True\n        else:\n            print(\"Model deployment failed\")\n            return False\n\n    def is_deployment_approved(self, validation_report):\n        \"\"\"Check if deployment is approved based on validation.\"\"\"\n        summary = validation_report['summary']\n\n        # Check that transfer was successful and safety checks passed\n        return (summary.get('transfer_success', False) and\n                summary.get('safety_pass', False) and\n                summary.get('overall_risk', 1.0) < 0.5)  # Risk must be below 0.5\n\n    def serialize_model(self, model):\n        \"\"\"Serialize model for deployment.\"\"\"\n        import io\n        buf = io.BytesIO()\n        torch.save(model.state_dict(), buf)\n        return buf.getvalue()\n\n    def rollback_model(self):\n        \"\"\"Rollback to previous model if current model fails.\"\"\"\n        print(\"Rolling back to previous model...\")\n        # Implementation would restore previous model\n        pass\n\n    def monitor_deployment(self):\n        \"\"\"Monitor deployed model performance.\"\"\"\n        print(\"Monitoring deployed model...\")\n        # Implementation would monitor real-world performance\n        pass\n\n# Example usage\nif __name__ == \"__main__\":\n    print(\"Transfer Validation and Deployment System\")\n\n    # Create validation system\n    validator = TransferValidationSystem()\n\n    # Define test scenarios\n    test_scenarios = [\n        {'name': 'navigation_easy', 'difficulty': 'easy'},\n        {'name': 'navigation_medium', 'difficulty': 'medium'},\n        {'name': 'navigation_hard', 'difficulty': 'hard'},\n        {'name': 'manipulation_simple', 'difficulty': 'easy'},\n        {'name': 'manipulation_complex', 'difficulty': 'hard'}\n    ]\n\n    # Define safety constraints\n    safety_constraints = [\n        {'name': 'position_limits', 'type': 'position_limit', 'limits': [(-10, 10), (-10, 10), (-1, 2)], 'critical': True},\n        {'name': 'velocity_limits', 'type': 'velocity_limit', 'limit': 2.0, 'critical': True},\n        {'name': 'acceleration_limits', 'type': 'velocity_limit', 'limit': 5.0, 'critical': False}\n    ]\n\n    # Run validation (simulated)\n    print(\"Running validation tests...\")\n    sim_results, real_results = validator.run_comparative_validation(\n        sim_model=\"dummy_sim_model\",\n        real_model=\"dummy_real_model\",\n        test_scenarios=test_scenarios\n    )\n\n    # Run safety validation\n    safety_results = validator.run_safety_validation(\n        model=\"dummy_model\",\n        safety_constraints=safety_constraints\n    )\n\n    # Generate validation report\n    report_path = validator.generate_validation_report()\n\n    print(f\"\\nValidation completed. Report saved to: {report_path}\")\n\n    # Example deployment (simulated)\n    print(\"\\nSimulating model deployment...\")\n\n    class DummyRobotInterface:\n        def deploy_model(self, model_bytes):\n            print(\"Deploying model to dummy robot interface...\")\n            return True  # Simulate successful deployment\n\n    robot_interface = DummyRobotInterface()\n    deployment_manager = DeploymentManager(\"model_path\", robot_interface)\n\n    # Simulate deploying a dummy model\n    dummy_model = torch.nn.Linear(3, 3)  # Dummy model\n    deployment_success = deployment_manager.deploy_model(dummy_model, validator.validation_results)\n\n    if deployment_success:\n        print(\"Model deployment successful!\")\n    else:\n        print(\"Model deployment failed.\")\n\n    print(\"\\nTransfer validation and deployment system completed successfully\")\n"})}),"\n",(0,a.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,a.jsx)(n.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Large reality gap after domain randomization"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Start with narrower randomization ranges"}),"\n",(0,a.jsx)(n.li,{children:"Use curriculum-based randomization"}),"\n",(0,a.jsx)(n.li,{children:"Add more diverse simulation scenarios"}),"\n",(0,a.jsx)(n.li,{children:"Validate intermediate models"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Poor transfer performance"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Collect more real-world data for adaptation"}),"\n",(0,a.jsx)(n.li,{children:"Use ensemble methods for robustness"}),"\n",(0,a.jsx)(n.li,{children:"Implement online adaptation"}),"\n",(0,a.jsx)(n.li,{children:"Revisit system identification"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Safety violations in real deployment"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Implement comprehensive safety checks"}),"\n",(0,a.jsx)(n.li,{children:"Use safety filters and barriers"}),"\n",(0,a.jsx)(n.li,{children:"Start with conservative parameters"}),"\n",(0,a.jsx)(n.li,{children:"Gradually increase capabilities"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Model overfitting to simulation"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Increase domain randomization diversity"}),"\n",(0,a.jsx)(n.li,{children:"Use regularization techniques"}),"\n",(0,a.jsx)(n.li,{children:"Implement early stopping"}),"\n",(0,a.jsx)(n.li,{children:"Add more real-world data"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Computational resource limitations"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Use model compression techniques"}),"\n",(0,a.jsx)(n.li,{children:"Implement efficient inference"}),"\n",(0,a.jsx)(n.li,{children:"Use quantization for deployment"}),"\n",(0,a.jsx)(n.li,{children:"Optimize neural network architecture"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"How do you quantify the reality gap between simulation and reality?"}),"\n",(0,a.jsx)(n.li,{children:"What are the key differences between domain randomization and system identification?"}),"\n",(0,a.jsx)(n.li,{children:"How would you design safety validation tests for robot deployment?"}),"\n",(0,a.jsx)(n.li,{children:"What metrics would you use to evaluate transfer effectiveness?"}),"\n",(0,a.jsx)(n.li,{children:"How do you handle model adaptation with limited real-world data?"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"extension-exercises",children:"Extension Exercises"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Implement meta-learning for rapid adaptation"}),"\n",(0,a.jsx)(n.li,{children:"Create a curriculum learning system for complex tasks"}),"\n",(0,a.jsx)(n.li,{children:"Implement adversarial domain adaptation techniques"}),"\n",(0,a.jsx)(n.li,{children:"Create a safety-critical deployment pipeline"}),"\n",(0,a.jsx)(n.li,{children:"Implement lifelong learning for continuous adaptation"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"In this lab, you successfully:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Analyzed and quantified the reality gap between simulation and reality"}),"\n",(0,a.jsx)(n.li,{children:"Implemented domain randomization techniques for robust simulation"}),"\n",(0,a.jsx)(n.li,{children:"Performed system identification to model real robot dynamics"}),"\n",(0,a.jsx)(n.li,{children:"Created model adaptation and fine-tuning systems"}),"\n",(0,a.jsx)(n.li,{children:"Developed validation and deployment procedures for safe transfer"}),"\n",(0,a.jsx)(n.li,{children:"Validated transfer effectiveness and safety measures"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"These skills are essential for bridging the gap between simulation and real-world robotics. The combination of domain randomization, system identification, model adaptation, and rigorous validation enables the development of robust robotic systems that can effectively transfer from simulation to real-world deployment while maintaining safety and performance guarantees."})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var a=t(6540);const i={},s=a.createContext(i);function r(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);