"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[8376],{3064:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var t=a(4848),s=a(8453);const i={},o="Lab 3.1: NVIDIA Isaac Navigation System",r={id:"modules/lab-exercises/lab-3-1-isaac-navigation",title:"Lab 3.1: NVIDIA Isaac Navigation System",description:"Overview",source:"@site/docs/modules/lab-exercises/lab-3-1-isaac-navigation.md",sourceDirName:"modules/lab-exercises",slug:"/modules/lab-exercises/lab-3-1-isaac-navigation",permalink:"/ai-robotic-book/modules/lab-exercises/lab-3-1-isaac-navigation",draft:!1,unlisted:!1,editUrl:"https://github.com/your-org/physical-ai-book/tree/main/docs/modules/lab-exercises/lab-3-1-isaac-navigation.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Reinforcement Learning",permalink:"/ai-robotic-book/modules/ai-robot-brain/reinforcement-learning"},next:{title:"Lab 3.1: Isaac Sim Setup and Environment",permalink:"/ai-robotic-book/modules/lab-exercises/lab-3-1-isaac-sim-setup"}},l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Theory Background",id:"theory-background",level:2},{value:"Lab Exercise",id:"lab-exercise",level:2},{value:"Part 1: Isaac Sim Environment Setup",id:"part-1-isaac-sim-environment-setup",level:3},{value:"Part 2: Isaac ROS Perception Pipeline",id:"part-2-isaac-ros-perception-pipeline",level:3},{value:"Part 3: Isaac SLAM Implementation",id:"part-3-isaac-slam-implementation",level:3},{value:"Part 4: Isaac Path Planning",id:"part-4-isaac-path-planning",level:3},{value:"Part 5: Isaac Navigation Stack Integration",id:"part-5-isaac-navigation-stack-integration",level:3},{value:"Implementation Steps",id:"implementation-steps",level:2},{value:"Expected Outcomes",id:"expected-outcomes",level:2},{value:"Troubleshooting Tips",id:"troubleshooting-tips",level:2},{value:"Further Exploration",id:"further-exploration",level:2}];function p(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"lab-31-nvidia-isaac-navigation-system",children:"Lab 3.1: NVIDIA Isaac Navigation System"}),"\n",(0,t.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(e.p,{children:"This lab exercise focuses on implementing navigation systems using NVIDIA Isaac Sim and Isaac ROS packages. Students will learn to build autonomous navigation capabilities for humanoid robots using advanced perception and planning algorithms optimized for NVIDIA hardware."}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this lab, students will be able to:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Configure NVIDIA Isaac Sim for humanoid robot navigation simulation"}),"\n",(0,t.jsx)(e.li,{children:"Implement perception pipelines using Isaac ROS packages"}),"\n",(0,t.jsx)(e.li,{children:"Set up SLAM (Simultaneous Localization and Mapping) systems"}),"\n",(0,t.jsx)(e.li,{children:"Create path planning and obstacle avoidance algorithms"}),"\n",(0,t.jsx)(e.li,{children:"Deploy navigation systems on NVIDIA Jetson platforms"}),"\n",(0,t.jsx)(e.li,{children:"Evaluate navigation performance using standard metrics"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Completion of Module 1: ROS 2 Fundamentals"}),"\n",(0,t.jsx)(e.li,{children:"Basic understanding of navigation concepts (path planning, SLAM)"}),"\n",(0,t.jsx)(e.li,{children:"Familiarity with NVIDIA Isaac ecosystem"}),"\n",(0,t.jsx)(e.li,{children:"Access to NVIDIA GPU or Jetson development kit"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"theory-background",children:"Theory Background"}),"\n",(0,t.jsx)(e.p,{children:"NVIDIA Isaac navigation systems leverage GPU-accelerated algorithms for real-time perception, mapping, and planning. Key components include:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Isaac Sim"}),": NVIDIA's robotics simulator with realistic physics and sensor simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Isaac ROS"}),": GPU-accelerated ROS packages for perception, navigation, and manipulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"SLAM Algorithms"}),": GPU-accelerated simultaneous localization and mapping"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Path Planning"}),": GPU-accelerated global and local planners"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Perception Pipeline"}),": Real-time sensor processing using CUDA and TensorRT"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"lab-exercise",children:"Lab Exercise"}),"\n",(0,t.jsx)(e.h3,{id:"part-1-isaac-sim-environment-setup",children:"Part 1: Isaac Sim Environment Setup"}),"\n",(0,t.jsx)(e.p,{children:"First, let's set up the Isaac Sim environment for navigation:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Isaac Sim navigation environment setup\nimport omni\nfrom pxr import Gf, UsdGeom, Sdf\nimport carb\nimport omni.kit.commands\nimport numpy as np\n\nclass IsaacSimNavigationEnvironment:\n    def __init__(self):\n        self.world = None\n        self.robot = None\n        self.navigation_map = None\n\n    def create_navigation_world(self):\n        """Create a navigation world with obstacles and waypoints"""\n        # Get the stage\n        stage = omni.usd.get_context().get_stage()\n\n        # Create ground plane\n        omni.kit.commands.execute(\n            "CreateMeshPrimWithDefaultXform",\n            prim_type="Plane",\n            prim_path="/World/GroundPlane",\n            name="ground_plane",\n            size=10.0,\n            axis="Z"\n        )\n\n        # Create obstacles\n        self.create_obstacles(stage)\n\n        # Create navigation waypoints\n        self.create_waypoints(stage)\n\n        # Set up lighting\n        self.setup_lighting(stage)\n\n        print("Navigation world created successfully")\n\n    def create_obstacles(self, stage):\n        """Create navigation obstacles"""\n        # Create walls\n        for i, (pos, size) in enumerate([\n            ((5, 0, 0), (0.5, 10, 1)),\n            ((-5, 0, 0), (0.5, 10, 1)),\n            ((0, 5, 0), (10, 0.5, 1)),\n            ((0, -5, 0), (10, 0.5, 1))\n        ]):\n            omni.kit.commands.execute(\n                "CreateMeshPrimWithDefaultXform",\n                prim_type="Cube",\n                prim_path=f"/World/Obstacle{i}",\n                name=f"obstacle{i}",\n                size=1.0\n            )\n\n            # Set position and scale\n            prim = stage.GetPrimAtPath(f"/World/Obstacle{i}")\n            xform = UsdGeom.Xformable(prim)\n            xform.AddTranslateOp().Set(Gf.Vec3d(*pos))\n            xform.AddScaleOp().Set(Gf.Vec3d(*size))\n\n    def create_waypoints(self, stage):\n        """Create navigation waypoints"""\n        waypoints = [\n            (0, 0, 0),      # Start\n            (2, 2, 0),      # Waypoint 1\n            (4, 0, 0),      # Waypoint 2\n            (2, -2, 0),     # Waypoint 3\n            (0, 0, 0)       # Return to start\n        ]\n\n        for i, pos in enumerate(waypoints):\n            omni.kit.commands.execute(\n                "CreateMeshPrimWithDefaultXform",\n                prim_type="Sphere",\n                prim_path=f"/World/Waypoint{i}",\n                name=f"waypoint{i}",\n                radius=0.2\n            )\n\n            # Set position\n            prim = stage.GetPrimAtPath(f"/World/Waypoint{i}")\n            xform = UsdGeom.Xformable(prim)\n            xform.AddTranslateOp().Set(Gf.Vec3d(*pos))\n\n    def setup_lighting(self, stage):\n        """Set up lighting for the scene"""\n        # Create dome light\n        omni.kit.commands.execute(\n            "CreatePrimWithDefaultXform",\n            prim_type="DomeLight",\n            prim_path="/World/DomeLight",\n            name="dome_light"\n        )\n\n        # Create distant light\n        omni.kit.commands.execute(\n            "CreatePrimWithDefaultXform",\n            prim_type="DistantLight",\n            prim_path="/World/DistantLight",\n            name="distant_light"\n        )\n\n# Example usage\ndef setup_navigation_environment():\n    env = IsaacSimNavigationEnvironment()\n    env.create_navigation_world()\n    return env\n\nif __name__ == "__main__":\n    setup_navigation_environment()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"part-2-isaac-ros-perception-pipeline",children:"Part 2: Isaac ROS Perception Pipeline"}),"\n",(0,t.jsx)(e.p,{children:"Now let's implement the perception pipeline using Isaac ROS packages:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Image, PointCloud2\nfrom nav_msgs.msg import OccupancyGrid, Odometry\nfrom geometry_msgs.msg import PoseStamped, Twist\nfrom cv_bridge import CvBridge\nimport numpy as np\nimport torch\n\nclass IsaacROSPerceptionPipeline(Node):\n    def __init__(self):\n        super().__init__('isaac_ros_perception_pipeline')\n\n        # Initialize CV bridge\n        self.bridge = CvBridge()\n\n        # Publishers and subscribers\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10\n        )\n\n        self.image_sub = self.create_subscription(\n            Image,\n            '/camera/rgb/image_raw',\n            self.image_callback,\n            10\n        )\n\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            '/odom',\n            self.odom_callback,\n            10\n        )\n\n        self.map_pub = self.create_publisher(\n            OccupancyGrid,\n            '/map',\n            10\n        )\n\n        self.collision_pub = self.create_publisher(\n            Twist,\n            '/collision_avoidance/cmd_vel',\n            10\n        )\n\n        # Initialize perception models\n        self.initialize_perception_models()\n\n        # Internal state\n        self.current_scan = None\n        self.current_image = None\n        self.current_odom = None\n        self.map_resolution = 0.05  # 5cm resolution\n        self.map_width = 200  # 10m x 10m map\n        self.map_height = 200\n\n    def initialize_perception_models(self):\n        \"\"\"Initialize Isaac ROS perception models\"\"\"\n        # For this example, we'll use simple models\n        # In practice, these would be Isaac ROS packages like:\n        # - Isaac ROS Stereo DNN\n        # - Isaac ROS Point Cloud Segmentation\n        # - Isaac ROS Occupancy Grid Mapping\n\n        # Create a simple occupancy grid\n        self.occupancy_grid = np.zeros((self.map_height, self.map_width), dtype=np.int8)\n\n        self.get_logger().info('Isaac ROS perception pipeline initialized')\n\n    def scan_callback(self, msg):\n        \"\"\"Process LIDAR scan data\"\"\"\n        try:\n            # Convert scan to occupancy grid\n            self.current_scan = {\n                'ranges': np.array(msg.ranges),\n                'angle_min': msg.angle_min,\n                'angle_max': msg.angle_max,\n                'angle_increment': msg.angle_increment,\n                'time_increment': msg.time_increment,\n                'scan_time': msg.scan_time,\n                'range_min': msg.range_min,\n                'range_max': msg.range_max\n            }\n\n            # Update occupancy grid with scan data\n            self.update_occupancy_grid_from_scan(self.current_scan)\n\n            # Publish updated map\n            self.publish_occupancy_grid()\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing scan: {str(e)}')\n\n    def image_callback(self, msg):\n        \"\"\"Process camera image data\"\"\"\n        try:\n            # Convert ROS image to OpenCV\n            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n\n            # Process image for obstacle detection (simplified)\n            obstacles_detected = self.detect_obstacles_in_image(cv_image)\n\n            # If obstacles detected, publish collision avoidance command\n            if obstacles_detected:\n                self.publish_collision_avoidance_command()\n\n            self.current_image = cv_image\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing image: {str(e)}')\n\n    def odom_callback(self, msg):\n        \"\"\"Process odometry data\"\"\"\n        try:\n            self.current_odom = {\n                'pose': {\n                    'position': (msg.pose.pose.position.x, msg.pose.pose.position.y, msg.pose.pose.position.z),\n                    'orientation': (msg.pose.pose.orientation.x, msg.pose.pose.orientation.y,\n                                  msg.pose.pose.orientation.z, msg.pose.pose.orientation.w)\n                },\n                'twist': {\n                    'linear': (msg.twist.twist.linear.x, msg.twist.twist.linear.y, msg.twist.twist.linear.z),\n                    'angular': (msg.twist.twist.angular.x, msg.twist.twist.angular.y, msg.twist.twist.angular.z)\n                }\n            }\n\n            # Update robot position in occupancy grid\n            self.update_robot_position_in_map(self.current_odom)\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing odometry: {str(e)}')\n\n    def update_occupancy_grid_from_scan(self, scan_data):\n        \"\"\"Update occupancy grid based on LIDAR scan\"\"\"\n        # Convert scan ranges to grid coordinates\n        angles = np.arange(scan_data['angle_min'], scan_data['angle_max'], scan_data['angle_increment'])\n\n        # Robot position in grid coordinates (assuming robot is at center initially)\n        robot_x, robot_y = self.map_width // 2, self.map_height // 2\n\n        for i, (angle, range_val) in enumerate(zip(angles, scan_data['ranges'])):\n            if np.isnan(range_val) or range_val > scan_data['range_max']:\n                continue\n\n            # Calculate endpoint of ray\n            end_x = robot_x + int((range_val * np.cos(angle)) / self.map_resolution)\n            end_y = robot_y + int((range_val * np.sin(angle)) / self.map_resolution)\n\n            # Check bounds\n            if 0 <= end_x < self.map_width and 0 <= end_y < self.map_height:\n                # Mark endpoint as occupied if range is below threshold\n                if range_val < 1.0:  # 1m threshold for obstacles\n                    self.occupancy_grid[end_y, end_x] = 100  # Occupied\n                else:\n                    self.occupancy_grid[end_y, end_x] = 0    # Free space\n\n    def detect_obstacles_in_image(self, image):\n        \"\"\"Detect obstacles in camera image (simplified)\"\"\"\n        # Simple edge detection for obstacle detection\n        import cv2\n\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = cv2.Canny(gray, 50, 150)\n\n        # Count edge pixels in lower half of image (potential obstacles)\n        height, width = edges.shape\n        lower_half = edges[height//2:, :]\n        edge_count = np.sum(lower_half > 0)\n\n        # If many edges detected in lower half, likely obstacles\n        return edge_count > (height * width * 0.05)  # 5% threshold\n\n    def update_robot_position_in_map(self, odom_data):\n        \"\"\"Update robot position in occupancy grid\"\"\"\n        # Convert world coordinates to grid coordinates\n        world_x, world_y = odom_data['pose']['position'][0], odom_data['pose']['position'][1]\n        grid_x = int(world_x / self.map_resolution) + self.map_width // 2\n        grid_y = int(world_y / self.map_resolution) + self.map_height // 2\n\n        # Ensure within bounds\n        grid_x = max(0, min(self.map_width - 1, grid_x))\n        grid_y = max(0, min(self.map_height - 1, grid_y))\n\n        # Mark robot position (clear around it)\n        for dx in range(-2, 3):\n            for dy in range(-2, 3):\n                x, y = grid_x + dx, grid_y + dy\n                if 0 <= x < self.map_width and 0 <= y < self.map_height:\n                    self.occupancy_grid[y, x] = 0  # Free space around robot\n\n    def publish_occupancy_grid(self):\n        \"\"\"Publish occupancy grid message\"\"\"\n        from nav_msgs.msg import OccupancyGrid\n        from std_msgs.msg import Header\n        import time\n\n        msg = OccupancyGrid()\n        msg.header = Header()\n        msg.header.stamp = self.get_clock().now().to_msg()\n        msg.header.frame_id = \"map\"\n\n        msg.info.resolution = self.map_resolution\n        msg.info.width = self.map_width\n        msg.info.height = self.map_height\n        msg.info.origin.position.x = -self.map_width * self.map_resolution / 2\n        msg.info.origin.position.y = -self.map_height * self.map_resolution / 2\n\n        # Flatten grid for message\n        msg.data = self.occupancy_grid.flatten().tolist()\n\n        self.map_pub.publish(msg)\n\n    def publish_collision_avoidance_command(self):\n        \"\"\"Publish collision avoidance command\"\"\"\n        twist_msg = Twist()\n        # Simple collision avoidance: turn away from obstacles\n        twist_msg.linear.x = 0.0\n        twist_msg.angular.z = 0.5  # Turn right to avoid obstacle\n\n        self.collision_pub.publish(twist_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    perception_pipeline = IsaacROSPerceptionPipeline()\n\n    try:\n        rclpy.spin(perception_pipeline)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        perception_pipeline.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h3,{id:"part-3-isaac-slam-implementation",children:"Part 3: Isaac SLAM Implementation"}),"\n",(0,t.jsx)(e.p,{children:"Now let's implement a SLAM system using Isaac's capabilities:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Image, PointCloud2\nfrom nav_msgs.msg import Odometry, OccupancyGrid\nfrom geometry_msgs.msg import PoseWithCovarianceStamped, PointStamped\nfrom tf2_ros import TransformBroadcaster\nimport numpy as np\nimport cv2\nfrom scipy.spatial.transform import Rotation as R\nimport time\n\nclass IsaacSLAMNode(Node):\n    def __init__(self):\n        super().__init__('isaac_slam_node')\n\n        # Publishers and subscribers\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10\n        )\n\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            '/odom',\n            self.odom_callback,\n            10\n        )\n\n        self.map_pub = self.create_publisher(\n            OccupancyGrid,\n            '/map',\n            10\n        )\n\n        self.initial_pose_pub = self.create_publisher(\n            PoseWithCovarianceStamped,\n            '/initialpose',\n            10\n        )\n\n        # Transform broadcaster\n        self.tf_broadcaster = TransformBroadcaster(self)\n\n        # SLAM parameters\n        self.map_resolution = 0.05  # 5cm\n        self.map_width = 400  # 20m x 20m\n        self.map_height = 400\n        self.map_origin_x = -self.map_width * self.map_resolution / 2\n        self.map_origin_y = -self.map_height * self.map_resolution / 2\n\n        # Initialize SLAM components\n        self.initialize_slam()\n\n    def initialize_slam(self):\n        \"\"\"Initialize SLAM components\"\"\"\n        # Occupancy grid map\n        self.occupancy_map = np.zeros((self.map_height, self.map_height), dtype=np.int8)\n\n        # Robot pose\n        self.robot_pose = {\n            'x': 0.0,\n            'y': 0.0,\n            'theta': 0.0\n        }\n\n        # Previous odometry for motion model\n        self.prev_odom = None\n        self.prev_time = None\n\n        self.get_logger().info('Isaac SLAM initialized')\n\n    def scan_callback(self, msg):\n        \"\"\"Process LIDAR scan for mapping\"\"\"\n        try:\n            # Update map with current scan\n            self.update_map_with_scan(msg)\n\n            # Publish updated map\n            self.publish_map()\n\n            # Broadcast transform\n            self.broadcast_transform()\n\n        except Exception as e:\n            self.get_logger().error(f'Error in scan callback: {str(e)}')\n\n    def odom_callback(self, msg):\n        \"\"\"Process odometry for localization\"\"\"\n        try:\n            current_time = self.get_clock().now().nanoseconds / 1e9\n\n            if self.prev_odom is not None and self.prev_time is not None:\n                # Calculate motion since last update\n                dt = current_time - self.prev_time\n\n                # Extract pose and twist\n                pose = msg.pose.pose\n                twist = msg.twist.twist\n\n                # Update robot pose using motion model (simplified)\n                self.robot_pose['x'] += twist.linear.x * dt * np.cos(self.robot_pose['theta'])\n                self.robot_pose['y'] += twist.linear.x * dt * np.sin(self.robot_pose['theta'])\n                self.robot_pose['theta'] += twist.angular.z * dt\n\n            self.prev_odom = msg\n            self.prev_time = current_time\n\n        except Exception as e:\n            self.get_logger().error(f'Error in odom callback: {str(e)}')\n\n    def update_map_with_scan(self, scan_msg):\n        \"\"\"Update occupancy map with scan data\"\"\"\n        # Convert scan to grid coordinates\n        angles = np.arange(\n            scan_msg.angle_min,\n            scan_msg.angle_max,\n            scan_msg.angle_increment\n        )\n\n        # Get robot position in grid coordinates\n        grid_x = int((self.robot_pose['x'] - self.map_origin_x) / self.map_resolution)\n        grid_y = int((self.robot_pose['y'] - self.map_origin_y) / self.map_resolution)\n\n        # Ensure robot position is within bounds\n        grid_x = max(0, min(self.map_width - 1, grid_x))\n        grid_y = max(0, min(self.map_height - 1, grid_y))\n\n        # Process each scan ray\n        for i, (angle, range_val) in enumerate(zip(angles, scan_msg.ranges)):\n            if np.isnan(range_val) or range_val > scan_msg.range_max:\n                continue\n\n            # Calculate ray endpoint in world coordinates\n            world_end_x = self.robot_pose['x'] + range_val * np.cos(self.robot_pose['theta'] + angle)\n            world_end_y = self.robot_pose['y'] + range_val * np.sin(self.robot_pose['theta'] + angle)\n\n            # Convert to grid coordinates\n            end_grid_x = int((world_end_x - self.map_origin_x) / self.map_resolution)\n            end_grid_y = int((world_end_y - self.map_origin_y) / self.map_resolution)\n\n            # Ensure endpoint is within bounds\n            end_grid_x = max(0, min(self.map_width - 1, end_grid_x))\n            end_grid_y = max(0, min(self.map_height - 1, end_grid_y))\n\n            # Ray tracing to update occupancy\n            self.trace_ray(grid_x, grid_y, end_grid_x, end_grid_y, range_val < 3.0)  # Mark as occupied if < 3m\n\n    def trace_ray(self, start_x, start_y, end_x, end_y, hit_obstacle):\n        \"\"\"Trace ray and update occupancy grid\"\"\"\n        # Bresenham's line algorithm for ray tracing\n        dx = abs(end_x - start_x)\n        dy = abs(end_y - start_y)\n        x_step = 1 if end_x > start_x else -1\n        y_step = 1 if end_y > start_y else -1\n        error = dx - dy\n\n        x, y = start_x, start_y\n\n        while True:\n            # Check bounds\n            if not (0 <= x < self.map_width and 0 <= y < self.map_height):\n                break\n\n            # Update occupancy based on whether we hit an obstacle\n            if x == end_x and y == end_y and hit_obstacle:\n                # Hit obstacle - mark as occupied\n                if self.occupancy_map[y, x] < 50:\n                    self.occupancy_map[y, x] += 25\n                if self.occupancy_map[y, x] > 100:\n                    self.occupancy_map[y, x] = 100\n            else:\n                # Free space - decrease occupancy\n                if self.occupancy_map[y, x] > 0:\n                    self.occupancy_map[y, x] -= 10\n                if self.occupancy_map[y, x] < 0:\n                    self.occupancy_map[y, x] = 0\n\n            if x == end_x and y == end_y:\n                break\n\n            error2 = 2 * error\n            if error2 > -dy:\n                error -= dy\n                x += x_step\n            if error2 < dx:\n                error += dx\n                y += y_step\n\n    def publish_map(self):\n        \"\"\"Publish occupancy grid map\"\"\"\n        msg = OccupancyGrid()\n        msg.header.stamp = self.get_clock().now().to_msg()\n        msg.header.frame_id = \"map\"\n\n        msg.info.resolution = self.map_resolution\n        msg.info.width = self.map_width\n        msg.info.height = self.map_height\n        msg.info.origin.position.x = self.map_origin_x\n        msg.info.origin.position.y = self.map_origin_y\n\n        # Flatten map data\n        msg.data = self.occupancy_map.flatten().tolist()\n\n        self.map_pub.publish(msg)\n\n    def broadcast_transform(self):\n        \"\"\"Broadcast map -> odom transform\"\"\"\n        from geometry_msgs.msg import TransformStamped\n\n        t = TransformStamped()\n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = \"map\"\n        t.child_frame_id = \"odom\"\n\n        t.transform.translation.x = self.robot_pose['x']\n        t.transform.translation.y = self.robot_pose['y']\n        t.transform.translation.z = 0.0\n\n        # Convert angle to quaternion\n        from tf2_ros import transform_to_msg\n        rot = R.from_euler('z', self.robot_pose['theta'])\n        quat = rot.as_quat()\n        t.transform.rotation.x = quat[0]\n        t.transform.rotation.y = quat[1]\n        t.transform.rotation.z = quat[2]\n        t.transform.rotation.w = quat[3]\n\n        self.tf_broadcaster.sendTransform(t)\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    slam_node = IsaacSLAMNode()\n\n    try:\n        rclpy.spin(slam_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        slam_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h3,{id:"part-4-isaac-path-planning",children:"Part 4: Isaac Path Planning"}),"\n",(0,t.jsx)(e.p,{children:"Now let's implement path planning using Isaac's GPU-accelerated algorithms:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import numpy as np\nimport heapq\nfrom typing import List, Tuple, Optional\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom std_msgs.msg import Header\nimport time\n\nclass IsaacPathPlannerNode(Node):\n    def __init__(self):\n        super().__init__('isaac_path_planner')\n\n        # Publishers and subscribers\n        self.map_sub = self.create_subscription(\n            OccupancyGrid,\n            '/map',\n            self.map_callback,\n            10\n        )\n\n        self.goal_sub = self.create_subscription(\n            PoseStamped,\n            '/move_base_simple/goal',\n            self.goal_callback,\n            10\n        )\n\n        self.path_pub = self.create_publisher(\n            Path,\n            '/plan',\n            10\n        )\n\n        # Internal state\n        self.occupancy_map = None\n        self.map_info = None\n        self.current_goal = None\n        self.current_start = None\n\n        self.get_logger().info('Isaac Path Planner initialized')\n\n    def map_callback(self, msg):\n        \"\"\"Process occupancy grid map\"\"\"\n        try:\n            # Store map info\n            self.map_info = {\n                'resolution': msg.info.resolution,\n                'width': msg.info.width,\n                'height': msg.info.height,\n                'origin_x': msg.info.origin.position.x,\n                'origin_y': msg.info.origin.position.y\n            }\n\n            # Convert map data to 2D array\n            self.occupancy_map = np.array(msg.data).reshape(\n                self.map_info['height'],\n                self.map_info['width']\n            ).astype(np.int8)\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing map: {str(e)}')\n\n    def goal_callback(self, msg):\n        \"\"\"Process goal pose and plan path\"\"\"\n        try:\n            if self.occupancy_map is None:\n                self.get_logger().warn('No map available, cannot plan path')\n                return\n\n            # Convert goal to map coordinates\n            goal_x = int((msg.pose.position.x - self.map_info['origin_x']) / self.map_info['resolution'])\n            goal_y = int((msg.pose.position.y - self.map_info['origin_y']) / self.map_info['resolution'])\n\n            # Get current robot position (simplified - assume at center initially)\n            start_x = self.map_info['width'] // 2\n            start_y = self.map_info['height'] // 2\n\n            # Plan path\n            path = self.plan_path((start_x, start_y), (goal_x, goal_y))\n\n            if path:\n                # Publish path\n                self.publish_path(path, msg.header.frame_id)\n                self.get_logger().info(f'Path planned with {len(path)} waypoints')\n            else:\n                self.get_logger().warn('No valid path found to goal')\n\n        except Exception as e:\n            self.get_logger().error(f'Error planning path: {str(e)}')\n\n    def plan_path(self, start: Tuple[int, int], goal: Tuple[int, int]) -> Optional[List[Tuple[int, int]]]:\n        \"\"\"Plan path using A* algorithm with GPU acceleration considerations\"\"\"\n        # Check if start and goal are valid\n        if not self.is_valid_cell(start[0], start[1]) or not self.is_valid_cell(goal[0], goal[1]):\n            return None\n\n        # Check if start and goal are in free space\n        if self.occupancy_map[start[1], start[0]] > 50 or self.occupancy_map[goal[1], goal[0]] > 50:\n            return None\n\n        # A* pathfinding algorithm\n        open_set = [(0, start)]\n        came_from = {}\n        g_score = {start: 0}\n        f_score = {start: self.heuristic(start, goal)}\n\n        while open_set:\n            current = heapq.heappop(open_set)[1]\n\n            if current == goal:\n                # Reconstruct path\n                path = []\n                while current in came_from:\n                    path.append(current)\n                    current = came_from[current]\n                path.append(start)\n                path.reverse()\n                return path\n\n            for neighbor in self.get_neighbors(current):\n                tentative_g_score = g_score[current] + self.distance(current, neighbor)\n\n                if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g_score\n                    f_score[neighbor] = tentative_g_score + self.heuristic(neighbor, goal)\n                    heapq.heappush(open_set, (f_score[neighbor], neighbor))\n\n        return None  # No path found\n\n    def heuristic(self, a: Tuple[int, int], b: Tuple[int, int]) -> float:\n        \"\"\"Heuristic function for A* (Euclidean distance)\"\"\"\n        return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n\n    def distance(self, a: Tuple[int, int], b: Tuple[int, int]) -> float:\n        \"\"\"Distance between two cells\"\"\"\n        return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n\n    def get_neighbors(self, pos: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"Get valid neighboring cells\"\"\"\n        neighbors = []\n        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1),  # 4-connectivity\n                       (-1, -1), (-1, 1), (1, -1), (1, 1)]:  # 8-connectivity if needed\n            new_x, new_y = pos[0] + dx, pos[1] + dy\n\n            if self.is_valid_cell(new_x, new_y) and self.occupancy_map[new_y, new_x] < 50:\n                neighbors.append((new_x, new_y))\n\n        return neighbors\n\n    def is_valid_cell(self, x: int, y: int) -> bool:\n        \"\"\"Check if cell coordinates are valid\"\"\"\n        if self.occupancy_map is None:\n            return False\n        return 0 <= x < self.map_info['width'] and 0 <= y < self.map_info['height']\n\n    def publish_path(self, path: List[Tuple[int, int]], frame_id: str):\n        \"\"\"Publish path as Path message\"\"\"\n        path_msg = Path()\n        path_msg.header = Header()\n        path_msg.header.stamp = self.get_clock().now().to_msg()\n        path_msg.header.frame_id = frame_id\n\n        for x, y in path:\n            # Convert grid coordinates back to world coordinates\n            world_x = x * self.map_info['resolution'] + self.map_info['origin_x']\n            world_y = y * self.map_info['resolution'] + self.map_info['origin_y']\n\n            pose_stamped = PoseStamped()\n            pose_stamped.pose.position.x = world_x\n            pose_stamped.pose.position.y = world_y\n            pose_stamped.pose.position.z = 0.0\n            pose_stamped.pose.orientation.w = 1.0\n\n            path_msg.poses.append(pose_stamped)\n\n        self.path_pub.publish(path_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    path_planner = IsaacPathPlannerNode()\n\n    try:\n        rclpy.spin(path_planner)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        path_planner.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h3,{id:"part-5-isaac-navigation-stack-integration",children:"Part 5: Isaac Navigation Stack Integration"}),"\n",(0,t.jsx)(e.p,{children:"Finally, let's create a complete navigation stack integration:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Odometry, Path\nfrom sensor_msgs.msg import LaserScan\nfrom std_msgs.msg import String\nimport numpy as np\nfrom typing import Dict, Any\n\nclass IsaacNavigationStack(Node):\n    def __init__(self):\n        super().__init__(\'isaac_navigation_stack\')\n\n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.status_pub = self.create_publisher(String, \'/navigation_status\', 10)\n\n        # Subscribers\n        self.odom_sub = self.create_subscription(Odometry, \'/odom\', self.odom_callback, 10)\n        self.scan_sub = self.create_subscription(LaserScan, \'/scan\', self.scan_callback, 10)\n        self.path_sub = self.create_subscription(Path, \'/plan\', self.path_callback, 10)\n        self.goal_sub = self.create_subscription(PoseStamped, \'/move_base_simple/goal\', self.goal_callback, 10)\n\n        # Navigation parameters\n        self.linear_vel = 0.5  # m/s\n        self.angular_vel = 0.5  # rad/s\n        self.safe_distance = 0.5  # meters\n        self.arrival_threshold = 0.3  # meters\n\n        # Internal state\n        self.current_pose = None\n        self.current_scan = None\n        self.current_path = []\n        self.current_goal = None\n        self.navigation_active = False\n        self.path_index = 0\n\n        # Create timer for navigation loop\n        self.nav_timer = self.create_timer(0.1, self.navigation_loop)\n\n        self.get_logger().info(\'Isaac Navigation Stack initialized\')\n\n    def odom_callback(self, msg):\n        """Update current pose from odometry"""\n        self.current_pose = {\n            \'x\': msg.pose.pose.position.x,\n            \'y\': msg.pose.pose.position.y,\n            \'theta\': self.quaternion_to_yaw(msg.pose.pose.orientation)\n        }\n\n    def scan_callback(self, msg):\n        """Update current scan data"""\n        self.current_scan = {\n            \'ranges\': np.array(msg.ranges),\n            \'angle_min\': msg.angle_min,\n            \'angle_max\': msg.angle_max,\n            \'angle_increment\': msg.angle_increment\n        }\n\n    def path_callback(self, msg):\n        """Update current path"""\n        self.current_path = []\n        for pose_stamped in msg.poses:\n            self.current_path.append({\n                \'x\': pose_stamped.pose.position.x,\n                \'y\': pose_stamped.pose.position.y\n            })\n        self.path_index = 0\n        self.navigation_active = len(self.current_path) > 0\n\n    def goal_callback(self, msg):\n        """Handle new goal"""\n        self.current_goal = {\n            \'x\': msg.pose.position.x,\n            \'y\': msg.pose.position.y\n        }\n        self.get_logger().info(f\'New goal received: ({self.current_goal["x"]:.2f}, {self.current_goal["y"]:.2f})\')\n\n    def quaternion_to_yaw(self, orientation):\n        """Convert quaternion to yaw angle"""\n        import math\n        siny_cosp = 2 * (orientation.w * orientation.z + orientation.x * orientation.y)\n        cosy_cosp = 1 - 2 * (orientation.y * orientation.y + orientation.z * orientation.z)\n        return math.atan2(siny_cosp, cosy_cosp)\n\n    def navigation_loop(self):\n        """Main navigation loop"""\n        if not self.current_pose or not self.navigation_active:\n            return\n\n        if not self.current_path or self.path_index >= len(self.current_path):\n            self.navigation_active = False\n            self.publish_status("Navigation completed")\n            self.stop_robot()\n            return\n\n        # Get current target waypoint\n        target = self.current_path[self.path_index]\n\n        # Check for obstacles\n        if self.detect_obstacles():\n            self.publish_status("Obstacle detected, stopping")\n            self.stop_robot()\n            return\n\n        # Calculate direction to target\n        dx = target[\'x\'] - self.current_pose[\'x\']\n        dy = target[\'y\'] - self.current_pose[\'y\']\n        distance_to_target = np.sqrt(dx**2 + dy**2)\n\n        # Check if reached current waypoint\n        if distance_to_target < self.arrival_threshold:\n            self.path_index += 1\n            if self.path_index >= len(self.current_path):\n                self.navigation_active = False\n                self.publish_status("Navigation completed")\n                self.stop_robot()\n                return\n            else:\n                # Move to next waypoint\n                target = self.current_path[self.path_index]\n                dx = target[\'x\'] - self.current_pose[\'x\']\n                dy = target[\'y\'] - self.current_pose[\'y\']\n                distance_to_target = np.sqrt(dx**2 + dy**2)\n\n        # Calculate desired heading\n        desired_theta = np.arctan2(dy, dx)\n        angle_diff = desired_theta - self.current_pose[\'theta\']\n\n        # Normalize angle difference\n        while angle_diff > np.pi:\n            angle_diff -= 2 * np.pi\n        while angle_diff < -np.pi:\n            angle_diff += 2 * np.pi\n\n        # Create command\n        cmd = Twist()\n\n        # Angular control\n        if abs(angle_diff) > 0.1:  # 0.1 rad = ~5.7 degrees\n            cmd.angular.z = np.clip(angle_diff * 1.5, -self.angular_vel, self.angular_vel)\n        else:\n            # Linear control\n            cmd.linear.x = np.clip(distance_to_target * 1.0, 0.0, self.linear_vel)\n\n        # Publish command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Update status\n        self.publish_status(f"Moving to waypoint {self.path_index + 1}/{len(self.current_path)}, "\n                           f"distance: {distance_to_target:.2f}m")\n\n    def detect_obstacles(self) -> bool:\n        """Detect obstacles in front of robot"""\n        if not self.current_scan:\n            return False\n\n        # Check forward-facing range (simplified)\n        forward_ranges = self.current_scan[\'ranges\'][720:1080]  # Assuming 1440 points for 360 deg\n        min_range = np.min(forward_ranges[np.isfinite(forward_ranges)]) if len(forward_ranges) > 0 else float(\'inf\')\n\n        return min_range < self.safe_distance\n\n    def stop_robot(self):\n        """Stop the robot"""\n        cmd = Twist()\n        cmd.linear.x = 0.0\n        cmd.angular.z = 0.0\n        self.cmd_vel_pub.publish(cmd)\n\n    def publish_status(self, status: str):\n        """Publish navigation status"""\n        status_msg = String()\n        status_msg.data = status\n        self.status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    nav_stack = IsaacNavigationStack()\n\n    try:\n        rclpy.spin(nav_stack)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        nav_stack.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Set up Isaac Sim environment for navigation simulation"}),"\n",(0,t.jsx)(e.li,{children:"Implement perception pipeline using Isaac ROS packages"}),"\n",(0,t.jsx)(e.li,{children:"Create SLAM system for mapping and localization"}),"\n",(0,t.jsx)(e.li,{children:"Develop path planning algorithms with GPU acceleration"}),"\n",(0,t.jsx)(e.li,{children:"Integrate complete navigation stack"}),"\n",(0,t.jsx)(e.li,{children:"Test navigation in simulated environment"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"expected-outcomes",children:"Expected Outcomes"}),"\n",(0,t.jsx)(e.p,{children:"After completing this lab, you should have:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"A working Isaac Sim environment with navigation scenarios"}),"\n",(0,t.jsx)(e.li,{children:"A perception pipeline that processes sensor data for navigation"}),"\n",(0,t.jsx)(e.li,{children:"A SLAM system that builds maps and localizes the robot"}),"\n",(0,t.jsx)(e.li,{children:"Path planning algorithms that compute optimal routes"}),"\n",(0,t.jsx)(e.li,{children:"A complete navigation stack that integrates all components"}),"\n",(0,t.jsx)(e.li,{children:"Evaluation metrics for navigation performance"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-tips",children:"Troubleshooting Tips"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Ensure Isaac Sim is properly installed with all dependencies"}),"\n",(0,t.jsx)(e.li,{children:"Verify GPU compatibility and CUDA installation"}),"\n",(0,t.jsx)(e.li,{children:"Check ROS 2 network configuration between simulation and perception nodes"}),"\n",(0,t.jsx)(e.li,{children:"Monitor memory usage during SLAM operations"}),"\n",(0,t.jsx)(e.li,{children:"Validate sensor data quality and calibration"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"further-exploration",children:"Further Exploration"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Implement more advanced SLAM algorithms (Cartographer, ORB-SLAM)"}),"\n",(0,t.jsx)(e.li,{children:"Add semantic mapping capabilities using Isaac ROS packages"}),"\n",(0,t.jsx)(e.li,{children:"Integrate reinforcement learning for adaptive navigation"}),"\n",(0,t.jsx)(e.li,{children:"Deploy on actual NVIDIA Jetson hardware"}),"\n",(0,t.jsx)(e.li,{children:"Add multi-robot coordination capabilities"}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(p,{...n})}):p(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>o,x:()=>r});var t=a(6540);const s={},i=t.createContext(s);function o(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),t.createElement(i.Provider,{value:e},n.children)}}}]);